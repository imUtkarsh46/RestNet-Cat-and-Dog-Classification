{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQmBXLYkcSVm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCfTPExwj-gG"
      },
      "outputs": [],
      "source": [
        "path_test = '/content/drive/MyDrive/ResNet Data/ResNet Data'\n",
        "category = ['Cats', 'Dogs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SC9m6FkWhv"
      },
      "outputs": [],
      "source": [
        "training = []\n",
        "def createTrainingData():\n",
        "    for cate in category:\n",
        "        path = os.path.join(path_test, cate)\n",
        "        class_num = category.index(cate)\n",
        "        for img in os.listdir(path):\n",
        "            img_array = cv2.imread(os.path.join(path, img))\n",
        "            # gray_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "            new_array = cv2.resize(img_array, (64, 64))\n",
        "            training.append([new_array, class_num])\n",
        "createTrainingData()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk1ZSxE40J8l"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "y = []\n",
        "for img, cl in training:\n",
        "  x.append(img)\n",
        "  y.append(cl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI0gNAoEg2AQ"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxfI9LFZ3mHn",
        "outputId": "75e80791-01bc-454d-e04d-8a3a117066f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "type(x), type(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEG5U68N3orc"
      },
      "outputs": [],
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH6Yb6fb3vmL",
        "outputId": "c5422d90-5175-4c0d-bf7b-5db59bead3a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "type(x), type(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67Ogc0Cq3wjw",
        "outputId": "ceb00b57-f435-4188-a904-6b0353295ffa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((960, 64, 64, 3), (960,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvzFX5N-31Dg"
      },
      "outputs": [],
      "source": [
        "#y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8udFLa64CGrs",
        "outputId": "7258cc95-ff0f-4eaa-96e4-b76c57d5ef61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(960, 2)\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import np_utils\n",
        "Y = np_utils.to_categorical(y, 2)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcV-w5JQ34eb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, Y, test_size=0.3, random_state=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0egNIXs4Guj",
        "outputId": "206ffec0-a9e8-461e-bef9-3290702becf4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uKlOmMT4KST"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, Flatten, MaxPool2D, Dropout, RandomFlip, RandomRotation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGMlwfsh4lqR",
        "outputId": "774b2a52-0081-4ebb-907e-8236fbfb7913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2, 2, 2048)        23587712  \n",
            "                                                                 \n",
            " random_flip (RandomFlip)    (None, 2, 2, 2048)        0         \n",
            "                                                                 \n",
            " random_rotation (RandomRota  (None, 2, 2, 2048)       0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                131088    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,718,954\n",
            "Trainable params: 23,665,834\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "model = Sequential()\n",
        "model.add(resnet)\n",
        "\n",
        "# model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
        "# model.add(MaxPool2D((2,2), (1,1), 'same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Conv2D(32 , (3,3), activation = 'relu'))\n",
        "# model.add(MaxPool2D((2,2), (1,1), 'same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(RandomFlip(\"horizontal_and_vertical\"))\n",
        "model.add(RandomRotation(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation= 'relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(8, activation= 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x7QZQ146Ntg"
      },
      "outputs": [],
      "source": [
        "# cnt = 0\n",
        "# for layer in resnet.layers:\n",
        "#   cnt = cnt+1\n",
        "#   layer.trainable = False\n",
        "#   if (cnt>=120):\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMrwEjyC6rEl"
      },
      "outputs": [],
      "source": [
        "# model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXtmP8a87gHf"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(len(X_train),64,64,3)/255\n",
        "X_test = X_test.reshape(len(X_test),64,64,3)/255\n",
        "y_train = y_train.reshape(len(y_train),2)\n",
        "y_test = y_test.reshape(len(y_test),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWfLdgMA9pAt",
        "outputId": "f4f0a713-338d-45ba-d133-a96821af90cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((672, 64, 64, 3), (672, 2), (288, 64, 64, 3), (288, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_train.shape , y_train.shape , X_test.shape , y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G0-58-s77du"
      },
      "outputs": [],
      "source": [
        "opt = keras.optimizers.RMSprop(learning_rate=0.000001)\n",
        "model.compile(opt, 'binary_crossentropy', ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8Ft6ULh8uU6",
        "outputId": "a40d196c-e532-4bb7-a90e-58291f220602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "21/21 [==============================] - 29s 127ms/step - loss: 0.8591 - accuracy: 0.5372 - val_loss: 0.7336 - val_accuracy: 0.5069\n",
            "Epoch 2/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8972 - accuracy: 0.5000 - val_loss: 0.7236 - val_accuracy: 0.5174\n",
            "Epoch 3/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8752 - accuracy: 0.5179 - val_loss: 0.7208 - val_accuracy: 0.4722\n",
            "Epoch 4/1000\n",
            "21/21 [==============================] - 2s 72ms/step - loss: 0.8926 - accuracy: 0.5134 - val_loss: 0.7719 - val_accuracy: 0.5035\n",
            "Epoch 5/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8732 - accuracy: 0.5149 - val_loss: 0.8433 - val_accuracy: 0.4965\n",
            "Epoch 6/1000\n",
            "21/21 [==============================] - 2s 72ms/step - loss: 0.9045 - accuracy: 0.5045 - val_loss: 1.2135 - val_accuracy: 0.4826\n",
            "Epoch 7/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.8618 - accuracy: 0.5089 - val_loss: 1.9542 - val_accuracy: 0.4931\n",
            "Epoch 8/1000\n",
            "21/21 [==============================] - 2s 72ms/step - loss: 0.8989 - accuracy: 0.5104 - val_loss: 1.8583 - val_accuracy: 0.5035\n",
            "Epoch 9/1000\n",
            "21/21 [==============================] - 2s 72ms/step - loss: 0.8412 - accuracy: 0.5253 - val_loss: 1.8381 - val_accuracy: 0.5035\n",
            "Epoch 10/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8244 - accuracy: 0.5312 - val_loss: 2.0212 - val_accuracy: 0.5035\n",
            "Epoch 11/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8376 - accuracy: 0.5491 - val_loss: 1.7849 - val_accuracy: 0.5035\n",
            "Epoch 12/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8486 - accuracy: 0.5164 - val_loss: 1.4279 - val_accuracy: 0.4965\n",
            "Epoch 13/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8212 - accuracy: 0.4792 - val_loss: 0.9920 - val_accuracy: 0.5347\n",
            "Epoch 14/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8477 - accuracy: 0.4911 - val_loss: 0.9900 - val_accuracy: 0.5000\n",
            "Epoch 15/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8184 - accuracy: 0.5238 - val_loss: 1.2339 - val_accuracy: 0.4722\n",
            "Epoch 16/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7992 - accuracy: 0.5179 - val_loss: 1.4103 - val_accuracy: 0.4653\n",
            "Epoch 17/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7886 - accuracy: 0.5372 - val_loss: 1.5532 - val_accuracy: 0.4479\n",
            "Epoch 18/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.8100 - accuracy: 0.5476 - val_loss: 1.5508 - val_accuracy: 0.4792\n",
            "Epoch 19/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7661 - accuracy: 0.5521 - val_loss: 1.6014 - val_accuracy: 0.4583\n",
            "Epoch 20/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.8163 - accuracy: 0.5134 - val_loss: 1.5056 - val_accuracy: 0.4688\n",
            "Epoch 21/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7770 - accuracy: 0.5223 - val_loss: 1.3944 - val_accuracy: 0.4861\n",
            "Epoch 22/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7696 - accuracy: 0.5521 - val_loss: 1.3273 - val_accuracy: 0.4931\n",
            "Epoch 23/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7963 - accuracy: 0.5357 - val_loss: 1.2080 - val_accuracy: 0.4792\n",
            "Epoch 24/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7800 - accuracy: 0.5417 - val_loss: 1.1341 - val_accuracy: 0.4792\n",
            "Epoch 25/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7728 - accuracy: 0.5074 - val_loss: 1.0658 - val_accuracy: 0.4896\n",
            "Epoch 26/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7828 - accuracy: 0.5000 - val_loss: 1.0476 - val_accuracy: 0.4583\n",
            "Epoch 27/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7602 - accuracy: 0.5580 - val_loss: 1.0170 - val_accuracy: 0.4896\n",
            "Epoch 28/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7765 - accuracy: 0.5253 - val_loss: 0.9785 - val_accuracy: 0.5035\n",
            "Epoch 29/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7352 - accuracy: 0.5729 - val_loss: 0.9490 - val_accuracy: 0.5035\n",
            "Epoch 30/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7480 - accuracy: 0.5595 - val_loss: 0.9036 - val_accuracy: 0.5104\n",
            "Epoch 31/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7251 - accuracy: 0.5952 - val_loss: 0.8507 - val_accuracy: 0.5208\n",
            "Epoch 32/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7474 - accuracy: 0.5580 - val_loss: 0.8178 - val_accuracy: 0.5069\n",
            "Epoch 33/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7608 - accuracy: 0.5521 - val_loss: 0.7849 - val_accuracy: 0.5139\n",
            "Epoch 34/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7239 - accuracy: 0.5640 - val_loss: 0.7496 - val_accuracy: 0.5139\n",
            "Epoch 35/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7385 - accuracy: 0.5699 - val_loss: 0.7343 - val_accuracy: 0.5208\n",
            "Epoch 36/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7269 - accuracy: 0.5774 - val_loss: 0.7286 - val_accuracy: 0.4965\n",
            "Epoch 37/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7261 - accuracy: 0.5923 - val_loss: 0.7251 - val_accuracy: 0.5035\n",
            "Epoch 38/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7408 - accuracy: 0.5714 - val_loss: 0.7181 - val_accuracy: 0.5417\n",
            "Epoch 39/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7240 - accuracy: 0.5521 - val_loss: 0.7103 - val_accuracy: 0.5486\n",
            "Epoch 40/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.7220 - accuracy: 0.5729 - val_loss: 0.7145 - val_accuracy: 0.5139\n",
            "Epoch 41/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.7436 - accuracy: 0.5625 - val_loss: 0.7131 - val_accuracy: 0.5451\n",
            "Epoch 42/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.7026 - accuracy: 0.5640 - val_loss: 0.7115 - val_accuracy: 0.5660\n",
            "Epoch 43/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7074 - accuracy: 0.5878 - val_loss: 0.7131 - val_accuracy: 0.5278\n",
            "Epoch 44/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7114 - accuracy: 0.5923 - val_loss: 0.7126 - val_accuracy: 0.5451\n",
            "Epoch 45/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7191 - accuracy: 0.5848 - val_loss: 0.7204 - val_accuracy: 0.5139\n",
            "Epoch 46/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7144 - accuracy: 0.5804 - val_loss: 0.7215 - val_accuracy: 0.5104\n",
            "Epoch 47/1000\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 0.7040 - accuracy: 0.5714 - val_loss: 0.7226 - val_accuracy: 0.4861\n",
            "Epoch 48/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7130 - accuracy: 0.5863 - val_loss: 0.7186 - val_accuracy: 0.5139\n",
            "Epoch 49/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6863 - accuracy: 0.5923 - val_loss: 0.7187 - val_accuracy: 0.4896\n",
            "Epoch 50/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.7003 - accuracy: 0.5818 - val_loss: 0.7178 - val_accuracy: 0.5000\n",
            "Epoch 51/1000\n",
            "21/21 [==============================] - 2s 82ms/step - loss: 0.6791 - accuracy: 0.6027 - val_loss: 0.7140 - val_accuracy: 0.5208\n",
            "Epoch 52/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6816 - accuracy: 0.5997 - val_loss: 0.7116 - val_accuracy: 0.5243\n",
            "Epoch 53/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6803 - accuracy: 0.6190 - val_loss: 0.7077 - val_accuracy: 0.5486\n",
            "Epoch 54/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6929 - accuracy: 0.6086 - val_loss: 0.7030 - val_accuracy: 0.5486\n",
            "Epoch 55/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6908 - accuracy: 0.5938 - val_loss: 0.6934 - val_accuracy: 0.5660\n",
            "Epoch 56/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6857 - accuracy: 0.5818 - val_loss: 0.6865 - val_accuracy: 0.5764\n",
            "Epoch 57/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6734 - accuracy: 0.6205 - val_loss: 0.6819 - val_accuracy: 0.5729\n",
            "Epoch 58/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6866 - accuracy: 0.6027 - val_loss: 0.6770 - val_accuracy: 0.5799\n",
            "Epoch 59/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6565 - accuracy: 0.6429 - val_loss: 0.6739 - val_accuracy: 0.5799\n",
            "Epoch 60/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6643 - accuracy: 0.6116 - val_loss: 0.6706 - val_accuracy: 0.5764\n",
            "Epoch 61/1000\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 0.6639 - accuracy: 0.6071 - val_loss: 0.6685 - val_accuracy: 0.6007\n",
            "Epoch 62/1000\n",
            "21/21 [==============================] - 2s 82ms/step - loss: 0.6461 - accuracy: 0.6414 - val_loss: 0.6666 - val_accuracy: 0.6007\n",
            "Epoch 63/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6656 - accuracy: 0.6161 - val_loss: 0.6655 - val_accuracy: 0.6146\n",
            "Epoch 64/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6745 - accuracy: 0.6235 - val_loss: 0.6641 - val_accuracy: 0.6076\n",
            "Epoch 65/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6739 - accuracy: 0.6533 - val_loss: 0.6631 - val_accuracy: 0.6111\n",
            "Epoch 66/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.6559 - accuracy: 0.6637 - val_loss: 0.6623 - val_accuracy: 0.6076\n",
            "Epoch 67/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6708 - accuracy: 0.6146 - val_loss: 0.6607 - val_accuracy: 0.6076\n",
            "Epoch 68/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.6529 - accuracy: 0.6250 - val_loss: 0.6592 - val_accuracy: 0.6146\n",
            "Epoch 69/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6344 - accuracy: 0.6533 - val_loss: 0.6585 - val_accuracy: 0.6146\n",
            "Epoch 70/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.6281 - accuracy: 0.6801 - val_loss: 0.6576 - val_accuracy: 0.6215\n",
            "Epoch 71/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6577 - accuracy: 0.6250 - val_loss: 0.6566 - val_accuracy: 0.6250\n",
            "Epoch 72/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6562 - accuracy: 0.6429 - val_loss: 0.6562 - val_accuracy: 0.6181\n",
            "Epoch 73/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6574 - accuracy: 0.6458 - val_loss: 0.6556 - val_accuracy: 0.6146\n",
            "Epoch 74/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6362 - accuracy: 0.6562 - val_loss: 0.6546 - val_accuracy: 0.6111\n",
            "Epoch 75/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6408 - accuracy: 0.6518 - val_loss: 0.6534 - val_accuracy: 0.6146\n",
            "Epoch 76/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.6336 - accuracy: 0.6548 - val_loss: 0.6523 - val_accuracy: 0.6181\n",
            "Epoch 77/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6202 - accuracy: 0.6801 - val_loss: 0.6523 - val_accuracy: 0.6111\n",
            "Epoch 78/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.6661 - accuracy: 0.6190 - val_loss: 0.6519 - val_accuracy: 0.6111\n",
            "Epoch 79/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6273 - accuracy: 0.6443 - val_loss: 0.6508 - val_accuracy: 0.6076\n",
            "Epoch 80/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.6517 - accuracy: 0.6280 - val_loss: 0.6508 - val_accuracy: 0.6076\n",
            "Epoch 81/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6464 - accuracy: 0.6741 - val_loss: 0.6497 - val_accuracy: 0.6250\n",
            "Epoch 82/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.6173 - accuracy: 0.6815 - val_loss: 0.6488 - val_accuracy: 0.6181\n",
            "Epoch 83/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6259 - accuracy: 0.6667 - val_loss: 0.6477 - val_accuracy: 0.6146\n",
            "Epoch 84/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6286 - accuracy: 0.6741 - val_loss: 0.6463 - val_accuracy: 0.6111\n",
            "Epoch 85/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6239 - accuracy: 0.6756 - val_loss: 0.6466 - val_accuracy: 0.6181\n",
            "Epoch 86/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.6187 - accuracy: 0.6726 - val_loss: 0.6460 - val_accuracy: 0.6111\n",
            "Epoch 87/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.6255 - accuracy: 0.6830 - val_loss: 0.6450 - val_accuracy: 0.6076\n",
            "Epoch 88/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6374 - accuracy: 0.6548 - val_loss: 0.6437 - val_accuracy: 0.6042\n",
            "Epoch 89/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.6171 - accuracy: 0.6875 - val_loss: 0.6426 - val_accuracy: 0.6076\n",
            "Epoch 90/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6281 - accuracy: 0.6711 - val_loss: 0.6417 - val_accuracy: 0.6076\n",
            "Epoch 91/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6211 - accuracy: 0.6741 - val_loss: 0.6413 - val_accuracy: 0.6181\n",
            "Epoch 92/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6174 - accuracy: 0.6726 - val_loss: 0.6402 - val_accuracy: 0.6146\n",
            "Epoch 93/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6243 - accuracy: 0.6741 - val_loss: 0.6391 - val_accuracy: 0.6215\n",
            "Epoch 94/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6146 - accuracy: 0.7128 - val_loss: 0.6384 - val_accuracy: 0.6250\n",
            "Epoch 95/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6209 - accuracy: 0.6786 - val_loss: 0.6386 - val_accuracy: 0.6146\n",
            "Epoch 96/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6237 - accuracy: 0.6682 - val_loss: 0.6378 - val_accuracy: 0.6181\n",
            "Epoch 97/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6037 - accuracy: 0.6696 - val_loss: 0.6377 - val_accuracy: 0.6181\n",
            "Epoch 98/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.6069 - accuracy: 0.6890 - val_loss: 0.6378 - val_accuracy: 0.6181\n",
            "Epoch 99/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6283 - accuracy: 0.6905 - val_loss: 0.6366 - val_accuracy: 0.6285\n",
            "Epoch 100/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6035 - accuracy: 0.6890 - val_loss: 0.6359 - val_accuracy: 0.6250\n",
            "Epoch 101/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6092 - accuracy: 0.6548 - val_loss: 0.6355 - val_accuracy: 0.6250\n",
            "Epoch 102/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5983 - accuracy: 0.6726 - val_loss: 0.6343 - val_accuracy: 0.6354\n",
            "Epoch 103/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.6051 - accuracy: 0.6935 - val_loss: 0.6339 - val_accuracy: 0.6389\n",
            "Epoch 104/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5841 - accuracy: 0.7009 - val_loss: 0.6331 - val_accuracy: 0.6424\n",
            "Epoch 105/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.6057 - accuracy: 0.6771 - val_loss: 0.6325 - val_accuracy: 0.6389\n",
            "Epoch 106/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5875 - accuracy: 0.6979 - val_loss: 0.6315 - val_accuracy: 0.6354\n",
            "Epoch 107/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5883 - accuracy: 0.7188 - val_loss: 0.6310 - val_accuracy: 0.6424\n",
            "Epoch 108/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5906 - accuracy: 0.6949 - val_loss: 0.6296 - val_accuracy: 0.6458\n",
            "Epoch 109/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.6168 - accuracy: 0.6562 - val_loss: 0.6289 - val_accuracy: 0.6493\n",
            "Epoch 110/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5996 - accuracy: 0.6994 - val_loss: 0.6285 - val_accuracy: 0.6458\n",
            "Epoch 111/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.6099 - accuracy: 0.6682 - val_loss: 0.6286 - val_accuracy: 0.6458\n",
            "Epoch 112/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5718 - accuracy: 0.7307 - val_loss: 0.6284 - val_accuracy: 0.6493\n",
            "Epoch 113/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5858 - accuracy: 0.7098 - val_loss: 0.6279 - val_accuracy: 0.6493\n",
            "Epoch 114/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5936 - accuracy: 0.7158 - val_loss: 0.6267 - val_accuracy: 0.6458\n",
            "Epoch 115/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.6082 - accuracy: 0.6741 - val_loss: 0.6262 - val_accuracy: 0.6458\n",
            "Epoch 116/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5918 - accuracy: 0.6845 - val_loss: 0.6255 - val_accuracy: 0.6493\n",
            "Epoch 117/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5930 - accuracy: 0.7068 - val_loss: 0.6246 - val_accuracy: 0.6493\n",
            "Epoch 118/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5821 - accuracy: 0.7277 - val_loss: 0.6237 - val_accuracy: 0.6458\n",
            "Epoch 119/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5633 - accuracy: 0.7158 - val_loss: 0.6227 - val_accuracy: 0.6528\n",
            "Epoch 120/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5858 - accuracy: 0.7098 - val_loss: 0.6216 - val_accuracy: 0.6562\n",
            "Epoch 121/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5787 - accuracy: 0.7455 - val_loss: 0.6214 - val_accuracy: 0.6597\n",
            "Epoch 122/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5659 - accuracy: 0.7321 - val_loss: 0.6206 - val_accuracy: 0.6562\n",
            "Epoch 123/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5786 - accuracy: 0.7143 - val_loss: 0.6195 - val_accuracy: 0.6528\n",
            "Epoch 124/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5775 - accuracy: 0.7113 - val_loss: 0.6193 - val_accuracy: 0.6528\n",
            "Epoch 125/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5588 - accuracy: 0.7232 - val_loss: 0.6184 - val_accuracy: 0.6493\n",
            "Epoch 126/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5798 - accuracy: 0.7009 - val_loss: 0.6176 - val_accuracy: 0.6562\n",
            "Epoch 127/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5710 - accuracy: 0.7336 - val_loss: 0.6170 - val_accuracy: 0.6528\n",
            "Epoch 128/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5880 - accuracy: 0.6935 - val_loss: 0.6157 - val_accuracy: 0.6632\n",
            "Epoch 129/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5882 - accuracy: 0.7083 - val_loss: 0.6151 - val_accuracy: 0.6632\n",
            "Epoch 130/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5747 - accuracy: 0.7188 - val_loss: 0.6147 - val_accuracy: 0.6632\n",
            "Epoch 131/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5548 - accuracy: 0.7485 - val_loss: 0.6141 - val_accuracy: 0.6632\n",
            "Epoch 132/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5601 - accuracy: 0.7009 - val_loss: 0.6132 - val_accuracy: 0.6701\n",
            "Epoch 133/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5519 - accuracy: 0.7366 - val_loss: 0.6122 - val_accuracy: 0.6771\n",
            "Epoch 134/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5626 - accuracy: 0.7381 - val_loss: 0.6112 - val_accuracy: 0.6771\n",
            "Epoch 135/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5500 - accuracy: 0.7604 - val_loss: 0.6102 - val_accuracy: 0.6736\n",
            "Epoch 136/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5419 - accuracy: 0.7530 - val_loss: 0.6095 - val_accuracy: 0.6771\n",
            "Epoch 137/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5684 - accuracy: 0.7277 - val_loss: 0.6086 - val_accuracy: 0.6875\n",
            "Epoch 138/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5535 - accuracy: 0.7411 - val_loss: 0.6083 - val_accuracy: 0.6875\n",
            "Epoch 139/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5637 - accuracy: 0.7574 - val_loss: 0.6077 - val_accuracy: 0.6944\n",
            "Epoch 140/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5543 - accuracy: 0.7381 - val_loss: 0.6069 - val_accuracy: 0.6875\n",
            "Epoch 141/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5422 - accuracy: 0.7634 - val_loss: 0.6060 - val_accuracy: 0.6910\n",
            "Epoch 142/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5409 - accuracy: 0.7277 - val_loss: 0.6052 - val_accuracy: 0.6944\n",
            "Epoch 143/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5552 - accuracy: 0.7619 - val_loss: 0.6048 - val_accuracy: 0.6979\n",
            "Epoch 144/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5434 - accuracy: 0.7485 - val_loss: 0.6037 - val_accuracy: 0.6979\n",
            "Epoch 145/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5502 - accuracy: 0.7500 - val_loss: 0.6033 - val_accuracy: 0.6875\n",
            "Epoch 146/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5448 - accuracy: 0.7574 - val_loss: 0.6023 - val_accuracy: 0.6875\n",
            "Epoch 147/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5414 - accuracy: 0.7664 - val_loss: 0.6016 - val_accuracy: 0.6910\n",
            "Epoch 148/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5264 - accuracy: 0.7872 - val_loss: 0.6004 - val_accuracy: 0.6979\n",
            "Epoch 149/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5183 - accuracy: 0.7946 - val_loss: 0.5991 - val_accuracy: 0.6979\n",
            "Epoch 150/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5422 - accuracy: 0.7485 - val_loss: 0.5985 - val_accuracy: 0.6979\n",
            "Epoch 151/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5159 - accuracy: 0.7768 - val_loss: 0.5987 - val_accuracy: 0.7014\n",
            "Epoch 152/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5320 - accuracy: 0.7768 - val_loss: 0.5985 - val_accuracy: 0.7014\n",
            "Epoch 153/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5363 - accuracy: 0.7485 - val_loss: 0.5972 - val_accuracy: 0.6979\n",
            "Epoch 154/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5211 - accuracy: 0.7798 - val_loss: 0.5964 - val_accuracy: 0.6979\n",
            "Epoch 155/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5213 - accuracy: 0.7812 - val_loss: 0.5957 - val_accuracy: 0.7014\n",
            "Epoch 156/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.5414 - accuracy: 0.7411 - val_loss: 0.5950 - val_accuracy: 0.6979\n",
            "Epoch 157/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.5342 - accuracy: 0.7604 - val_loss: 0.5942 - val_accuracy: 0.6979\n",
            "Epoch 158/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5341 - accuracy: 0.7634 - val_loss: 0.5936 - val_accuracy: 0.7014\n",
            "Epoch 159/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5217 - accuracy: 0.7589 - val_loss: 0.5928 - val_accuracy: 0.7049\n",
            "Epoch 160/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5194 - accuracy: 0.7693 - val_loss: 0.5919 - val_accuracy: 0.7014\n",
            "Epoch 161/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5212 - accuracy: 0.7708 - val_loss: 0.5913 - val_accuracy: 0.6944\n",
            "Epoch 162/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5030 - accuracy: 0.7768 - val_loss: 0.5909 - val_accuracy: 0.7049\n",
            "Epoch 163/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5264 - accuracy: 0.7560 - val_loss: 0.5896 - val_accuracy: 0.7014\n",
            "Epoch 164/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5329 - accuracy: 0.7783 - val_loss: 0.5891 - val_accuracy: 0.7049\n",
            "Epoch 165/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5125 - accuracy: 0.7649 - val_loss: 0.5879 - val_accuracy: 0.7049\n",
            "Epoch 166/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5243 - accuracy: 0.7738 - val_loss: 0.5873 - val_accuracy: 0.6979\n",
            "Epoch 167/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5172 - accuracy: 0.7857 - val_loss: 0.5863 - val_accuracy: 0.6979\n",
            "Epoch 168/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.5216 - accuracy: 0.7545 - val_loss: 0.5853 - val_accuracy: 0.6979\n",
            "Epoch 169/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5149 - accuracy: 0.7545 - val_loss: 0.5843 - val_accuracy: 0.7014\n",
            "Epoch 170/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5246 - accuracy: 0.7619 - val_loss: 0.5835 - val_accuracy: 0.7049\n",
            "Epoch 171/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5146 - accuracy: 0.7708 - val_loss: 0.5826 - val_accuracy: 0.7014\n",
            "Epoch 172/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4968 - accuracy: 0.8021 - val_loss: 0.5822 - val_accuracy: 0.7014\n",
            "Epoch 173/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.5072 - accuracy: 0.7738 - val_loss: 0.5809 - val_accuracy: 0.7014\n",
            "Epoch 174/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5097 - accuracy: 0.7708 - val_loss: 0.5796 - val_accuracy: 0.7049\n",
            "Epoch 175/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.5021 - accuracy: 0.7798 - val_loss: 0.5795 - val_accuracy: 0.7014\n",
            "Epoch 176/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4843 - accuracy: 0.8006 - val_loss: 0.5787 - val_accuracy: 0.7049\n",
            "Epoch 177/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.4980 - accuracy: 0.7738 - val_loss: 0.5770 - val_accuracy: 0.7153\n",
            "Epoch 178/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5049 - accuracy: 0.7887 - val_loss: 0.5756 - val_accuracy: 0.7188\n",
            "Epoch 179/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4874 - accuracy: 0.7857 - val_loss: 0.5746 - val_accuracy: 0.7153\n",
            "Epoch 180/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4896 - accuracy: 0.8006 - val_loss: 0.5740 - val_accuracy: 0.7083\n",
            "Epoch 181/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4824 - accuracy: 0.7946 - val_loss: 0.5730 - val_accuracy: 0.7083\n",
            "Epoch 182/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5038 - accuracy: 0.7723 - val_loss: 0.5721 - val_accuracy: 0.7153\n",
            "Epoch 183/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4854 - accuracy: 0.8065 - val_loss: 0.5715 - val_accuracy: 0.7188\n",
            "Epoch 184/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.5068 - accuracy: 0.7976 - val_loss: 0.5714 - val_accuracy: 0.7257\n",
            "Epoch 185/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4750 - accuracy: 0.7961 - val_loss: 0.5700 - val_accuracy: 0.7257\n",
            "Epoch 186/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4874 - accuracy: 0.7693 - val_loss: 0.5693 - val_accuracy: 0.7222\n",
            "Epoch 187/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4956 - accuracy: 0.7902 - val_loss: 0.5694 - val_accuracy: 0.7153\n",
            "Epoch 188/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.4732 - accuracy: 0.7946 - val_loss: 0.5687 - val_accuracy: 0.7257\n",
            "Epoch 189/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4750 - accuracy: 0.8110 - val_loss: 0.5677 - val_accuracy: 0.7292\n",
            "Epoch 190/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4674 - accuracy: 0.8095 - val_loss: 0.5674 - val_accuracy: 0.7292\n",
            "Epoch 191/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4905 - accuracy: 0.8036 - val_loss: 0.5674 - val_accuracy: 0.7292\n",
            "Epoch 192/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4714 - accuracy: 0.8110 - val_loss: 0.5673 - val_accuracy: 0.7292\n",
            "Epoch 193/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4901 - accuracy: 0.7932 - val_loss: 0.5664 - val_accuracy: 0.7292\n",
            "Epoch 194/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4693 - accuracy: 0.8214 - val_loss: 0.5659 - val_accuracy: 0.7257\n",
            "Epoch 195/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4598 - accuracy: 0.8140 - val_loss: 0.5649 - val_accuracy: 0.7292\n",
            "Epoch 196/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4806 - accuracy: 0.8006 - val_loss: 0.5639 - val_accuracy: 0.7292\n",
            "Epoch 197/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4754 - accuracy: 0.8155 - val_loss: 0.5630 - val_accuracy: 0.7326\n",
            "Epoch 198/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4808 - accuracy: 0.7812 - val_loss: 0.5621 - val_accuracy: 0.7326\n",
            "Epoch 199/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4774 - accuracy: 0.7932 - val_loss: 0.5609 - val_accuracy: 0.7326\n",
            "Epoch 200/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4771 - accuracy: 0.8065 - val_loss: 0.5600 - val_accuracy: 0.7361\n",
            "Epoch 201/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4745 - accuracy: 0.7902 - val_loss: 0.5597 - val_accuracy: 0.7326\n",
            "Epoch 202/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4619 - accuracy: 0.8199 - val_loss: 0.5588 - val_accuracy: 0.7292\n",
            "Epoch 203/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4588 - accuracy: 0.8259 - val_loss: 0.5577 - val_accuracy: 0.7292\n",
            "Epoch 204/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4663 - accuracy: 0.8199 - val_loss: 0.5565 - val_accuracy: 0.7257\n",
            "Epoch 205/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4658 - accuracy: 0.8199 - val_loss: 0.5557 - val_accuracy: 0.7292\n",
            "Epoch 206/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4635 - accuracy: 0.8438 - val_loss: 0.5553 - val_accuracy: 0.7257\n",
            "Epoch 207/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4506 - accuracy: 0.8229 - val_loss: 0.5541 - val_accuracy: 0.7361\n",
            "Epoch 208/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4762 - accuracy: 0.7961 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
            "Epoch 209/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.4742 - accuracy: 0.8036 - val_loss: 0.5525 - val_accuracy: 0.7361\n",
            "Epoch 210/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4658 - accuracy: 0.8259 - val_loss: 0.5519 - val_accuracy: 0.7361\n",
            "Epoch 211/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4572 - accuracy: 0.8318 - val_loss: 0.5513 - val_accuracy: 0.7396\n",
            "Epoch 212/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4602 - accuracy: 0.8170 - val_loss: 0.5510 - val_accuracy: 0.7396\n",
            "Epoch 213/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4550 - accuracy: 0.8065 - val_loss: 0.5507 - val_accuracy: 0.7361\n",
            "Epoch 214/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4757 - accuracy: 0.8006 - val_loss: 0.5502 - val_accuracy: 0.7361\n",
            "Epoch 215/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4740 - accuracy: 0.8185 - val_loss: 0.5494 - val_accuracy: 0.7326\n",
            "Epoch 216/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4482 - accuracy: 0.8199 - val_loss: 0.5489 - val_accuracy: 0.7361\n",
            "Epoch 217/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4507 - accuracy: 0.8348 - val_loss: 0.5480 - val_accuracy: 0.7361\n",
            "Epoch 218/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4674 - accuracy: 0.8080 - val_loss: 0.5470 - val_accuracy: 0.7361\n",
            "Epoch 219/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4408 - accuracy: 0.8289 - val_loss: 0.5465 - val_accuracy: 0.7396\n",
            "Epoch 220/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.4498 - accuracy: 0.8229 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
            "Epoch 221/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4511 - accuracy: 0.8318 - val_loss: 0.5456 - val_accuracy: 0.7431\n",
            "Epoch 222/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4668 - accuracy: 0.8036 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
            "Epoch 223/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4425 - accuracy: 0.8542 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
            "Epoch 224/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4454 - accuracy: 0.8229 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 225/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4582 - accuracy: 0.8244 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
            "Epoch 226/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4538 - accuracy: 0.8244 - val_loss: 0.5439 - val_accuracy: 0.7431\n",
            "Epoch 227/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4566 - accuracy: 0.8185 - val_loss: 0.5432 - val_accuracy: 0.7431\n",
            "Epoch 228/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4323 - accuracy: 0.8467 - val_loss: 0.5429 - val_accuracy: 0.7431\n",
            "Epoch 229/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4200 - accuracy: 0.8304 - val_loss: 0.5425 - val_accuracy: 0.7431\n",
            "Epoch 230/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4376 - accuracy: 0.8304 - val_loss: 0.5418 - val_accuracy: 0.7431\n",
            "Epoch 231/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4227 - accuracy: 0.8467 - val_loss: 0.5418 - val_accuracy: 0.7396\n",
            "Epoch 232/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4233 - accuracy: 0.8363 - val_loss: 0.5411 - val_accuracy: 0.7396\n",
            "Epoch 233/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4577 - accuracy: 0.8289 - val_loss: 0.5402 - val_accuracy: 0.7431\n",
            "Epoch 234/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4471 - accuracy: 0.8185 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
            "Epoch 235/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4377 - accuracy: 0.8318 - val_loss: 0.5391 - val_accuracy: 0.7431\n",
            "Epoch 236/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4271 - accuracy: 0.8378 - val_loss: 0.5390 - val_accuracy: 0.7396\n",
            "Epoch 237/1000\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4209 - accuracy: 0.8512 - val_loss: 0.5385 - val_accuracy: 0.7431\n",
            "Epoch 238/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4388 - accuracy: 0.8214 - val_loss: 0.5375 - val_accuracy: 0.7431\n",
            "Epoch 239/1000\n",
            "21/21 [==============================] - 2s 83ms/step - loss: 0.4403 - accuracy: 0.8274 - val_loss: 0.5361 - val_accuracy: 0.7431\n",
            "Epoch 240/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4193 - accuracy: 0.8467 - val_loss: 0.5357 - val_accuracy: 0.7465\n",
            "Epoch 241/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4214 - accuracy: 0.8363 - val_loss: 0.5360 - val_accuracy: 0.7465\n",
            "Epoch 242/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4151 - accuracy: 0.8467 - val_loss: 0.5356 - val_accuracy: 0.7465\n",
            "Epoch 243/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.3970 - accuracy: 0.8557 - val_loss: 0.5346 - val_accuracy: 0.7431\n",
            "Epoch 244/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4157 - accuracy: 0.8408 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
            "Epoch 245/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4035 - accuracy: 0.8467 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 246/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.4295 - accuracy: 0.8259 - val_loss: 0.5329 - val_accuracy: 0.7535\n",
            "Epoch 247/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.4329 - accuracy: 0.8259 - val_loss: 0.5333 - val_accuracy: 0.7500\n",
            "Epoch 248/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.4166 - accuracy: 0.8348 - val_loss: 0.5329 - val_accuracy: 0.7535\n",
            "Epoch 249/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.4020 - accuracy: 0.8482 - val_loss: 0.5321 - val_accuracy: 0.7431\n",
            "Epoch 250/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4166 - accuracy: 0.8438 - val_loss: 0.5316 - val_accuracy: 0.7500\n",
            "Epoch 251/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4234 - accuracy: 0.8542 - val_loss: 0.5311 - val_accuracy: 0.7465\n",
            "Epoch 252/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4349 - accuracy: 0.8304 - val_loss: 0.5306 - val_accuracy: 0.7465\n",
            "Epoch 253/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3952 - accuracy: 0.8497 - val_loss: 0.5305 - val_accuracy: 0.7465\n",
            "Epoch 254/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.4239 - accuracy: 0.8259 - val_loss: 0.5296 - val_accuracy: 0.7465\n",
            "Epoch 255/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.4114 - accuracy: 0.8423 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
            "Epoch 256/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4062 - accuracy: 0.8601 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
            "Epoch 257/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3881 - accuracy: 0.8616 - val_loss: 0.5272 - val_accuracy: 0.7535\n",
            "Epoch 258/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3951 - accuracy: 0.8497 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
            "Epoch 259/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4037 - accuracy: 0.8705 - val_loss: 0.5261 - val_accuracy: 0.7639\n",
            "Epoch 260/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.4207 - accuracy: 0.8333 - val_loss: 0.5259 - val_accuracy: 0.7639\n",
            "Epoch 261/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3940 - accuracy: 0.8616 - val_loss: 0.5254 - val_accuracy: 0.7674\n",
            "Epoch 262/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.4018 - accuracy: 0.8586 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
            "Epoch 263/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3987 - accuracy: 0.8586 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
            "Epoch 264/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.4104 - accuracy: 0.8586 - val_loss: 0.5247 - val_accuracy: 0.7639\n",
            "Epoch 265/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.4124 - accuracy: 0.8378 - val_loss: 0.5245 - val_accuracy: 0.7639\n",
            "Epoch 266/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.4021 - accuracy: 0.8586 - val_loss: 0.5242 - val_accuracy: 0.7639\n",
            "Epoch 267/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3986 - accuracy: 0.8557 - val_loss: 0.5227 - val_accuracy: 0.7639\n",
            "Epoch 268/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3897 - accuracy: 0.8750 - val_loss: 0.5218 - val_accuracy: 0.7639\n",
            "Epoch 269/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.4207 - accuracy: 0.8542 - val_loss: 0.5214 - val_accuracy: 0.7639\n",
            "Epoch 270/1000\n",
            "21/21 [==============================] - 2s 91ms/step - loss: 0.4220 - accuracy: 0.8378 - val_loss: 0.5203 - val_accuracy: 0.7639\n",
            "Epoch 271/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3971 - accuracy: 0.8765 - val_loss: 0.5201 - val_accuracy: 0.7639\n",
            "Epoch 272/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3789 - accuracy: 0.8899 - val_loss: 0.5194 - val_accuracy: 0.7639\n",
            "Epoch 273/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3795 - accuracy: 0.8616 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 274/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.4012 - accuracy: 0.8557 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 275/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3697 - accuracy: 0.8869 - val_loss: 0.5193 - val_accuracy: 0.7743\n",
            "Epoch 276/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3937 - accuracy: 0.8586 - val_loss: 0.5184 - val_accuracy: 0.7743\n",
            "Epoch 277/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.4027 - accuracy: 0.8512 - val_loss: 0.5178 - val_accuracy: 0.7708\n",
            "Epoch 278/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3889 - accuracy: 0.8571 - val_loss: 0.5180 - val_accuracy: 0.7674\n",
            "Epoch 279/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3956 - accuracy: 0.8616 - val_loss: 0.5176 - val_accuracy: 0.7708\n",
            "Epoch 280/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3815 - accuracy: 0.8512 - val_loss: 0.5174 - val_accuracy: 0.7708\n",
            "Epoch 281/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3924 - accuracy: 0.8646 - val_loss: 0.5173 - val_accuracy: 0.7708\n",
            "Epoch 282/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3837 - accuracy: 0.8795 - val_loss: 0.5167 - val_accuracy: 0.7743\n",
            "Epoch 283/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3635 - accuracy: 0.8795 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
            "Epoch 284/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3825 - accuracy: 0.8527 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
            "Epoch 285/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3875 - accuracy: 0.8467 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
            "Epoch 286/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3780 - accuracy: 0.8661 - val_loss: 0.5144 - val_accuracy: 0.7778\n",
            "Epoch 287/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3821 - accuracy: 0.8780 - val_loss: 0.5128 - val_accuracy: 0.7778\n",
            "Epoch 288/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3890 - accuracy: 0.8497 - val_loss: 0.5126 - val_accuracy: 0.7778\n",
            "Epoch 289/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3955 - accuracy: 0.8571 - val_loss: 0.5128 - val_accuracy: 0.7778\n",
            "Epoch 290/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3753 - accuracy: 0.8720 - val_loss: 0.5121 - val_accuracy: 0.7778\n",
            "Epoch 291/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3924 - accuracy: 0.8452 - val_loss: 0.5123 - val_accuracy: 0.7743\n",
            "Epoch 292/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3872 - accuracy: 0.8676 - val_loss: 0.5120 - val_accuracy: 0.7778\n",
            "Epoch 293/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3719 - accuracy: 0.8631 - val_loss: 0.5122 - val_accuracy: 0.7812\n",
            "Epoch 294/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3853 - accuracy: 0.8646 - val_loss: 0.5113 - val_accuracy: 0.7847\n",
            "Epoch 295/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3715 - accuracy: 0.8720 - val_loss: 0.5101 - val_accuracy: 0.7778\n",
            "Epoch 296/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3605 - accuracy: 0.8869 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
            "Epoch 297/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3576 - accuracy: 0.8929 - val_loss: 0.5101 - val_accuracy: 0.7847\n",
            "Epoch 298/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3505 - accuracy: 0.8839 - val_loss: 0.5097 - val_accuracy: 0.7847\n",
            "Epoch 299/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3531 - accuracy: 0.8854 - val_loss: 0.5080 - val_accuracy: 0.7847\n",
            "Epoch 300/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3564 - accuracy: 0.8780 - val_loss: 0.5079 - val_accuracy: 0.7882\n",
            "Epoch 301/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3546 - accuracy: 0.8676 - val_loss: 0.5082 - val_accuracy: 0.7847\n",
            "Epoch 302/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3709 - accuracy: 0.8601 - val_loss: 0.5077 - val_accuracy: 0.7812\n",
            "Epoch 303/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3547 - accuracy: 0.8735 - val_loss: 0.5069 - val_accuracy: 0.7847\n",
            "Epoch 304/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3555 - accuracy: 0.8869 - val_loss: 0.5066 - val_accuracy: 0.7847\n",
            "Epoch 305/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3645 - accuracy: 0.8586 - val_loss: 0.5062 - val_accuracy: 0.7882\n",
            "Epoch 306/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3502 - accuracy: 0.8869 - val_loss: 0.5049 - val_accuracy: 0.7882\n",
            "Epoch 307/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.3687 - accuracy: 0.8616 - val_loss: 0.5043 - val_accuracy: 0.7882\n",
            "Epoch 308/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3699 - accuracy: 0.8631 - val_loss: 0.5036 - val_accuracy: 0.7882\n",
            "Epoch 309/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3618 - accuracy: 0.8824 - val_loss: 0.5035 - val_accuracy: 0.7847\n",
            "Epoch 310/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3264 - accuracy: 0.9003 - val_loss: 0.5029 - val_accuracy: 0.7882\n",
            "Epoch 311/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3572 - accuracy: 0.8795 - val_loss: 0.5027 - val_accuracy: 0.7882\n",
            "Epoch 312/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3676 - accuracy: 0.8690 - val_loss: 0.5022 - val_accuracy: 0.7882\n",
            "Epoch 313/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3453 - accuracy: 0.8676 - val_loss: 0.5013 - val_accuracy: 0.7882\n",
            "Epoch 314/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3425 - accuracy: 0.8735 - val_loss: 0.5014 - val_accuracy: 0.7882\n",
            "Epoch 315/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3560 - accuracy: 0.8631 - val_loss: 0.5005 - val_accuracy: 0.7882\n",
            "Epoch 316/1000\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.3539 - accuracy: 0.8750 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
            "Epoch 317/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.3567 - accuracy: 0.8869 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
            "Epoch 318/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3554 - accuracy: 0.8571 - val_loss: 0.4991 - val_accuracy: 0.7917\n",
            "Epoch 319/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.3617 - accuracy: 0.8899 - val_loss: 0.4981 - val_accuracy: 0.7917\n",
            "Epoch 320/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3492 - accuracy: 0.8914 - val_loss: 0.4980 - val_accuracy: 0.7917\n",
            "Epoch 321/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3644 - accuracy: 0.8646 - val_loss: 0.4980 - val_accuracy: 0.7917\n",
            "Epoch 322/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3493 - accuracy: 0.8929 - val_loss: 0.4981 - val_accuracy: 0.7917\n",
            "Epoch 323/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.3653 - accuracy: 0.8958 - val_loss: 0.4974 - val_accuracy: 0.7917\n",
            "Epoch 324/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3561 - accuracy: 0.8616 - val_loss: 0.4969 - val_accuracy: 0.7917\n",
            "Epoch 325/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3460 - accuracy: 0.8824 - val_loss: 0.4967 - val_accuracy: 0.7917\n",
            "Epoch 326/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3335 - accuracy: 0.8973 - val_loss: 0.4963 - val_accuracy: 0.7882\n",
            "Epoch 327/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3462 - accuracy: 0.8765 - val_loss: 0.4970 - val_accuracy: 0.7917\n",
            "Epoch 328/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3538 - accuracy: 0.8690 - val_loss: 0.4959 - val_accuracy: 0.7917\n",
            "Epoch 329/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3516 - accuracy: 0.8810 - val_loss: 0.4950 - val_accuracy: 0.7951\n",
            "Epoch 330/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3381 - accuracy: 0.8914 - val_loss: 0.4949 - val_accuracy: 0.7986\n",
            "Epoch 331/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3403 - accuracy: 0.8899 - val_loss: 0.4944 - val_accuracy: 0.7951\n",
            "Epoch 332/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3295 - accuracy: 0.8795 - val_loss: 0.4946 - val_accuracy: 0.7951\n",
            "Epoch 333/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3342 - accuracy: 0.8780 - val_loss: 0.4940 - val_accuracy: 0.7951\n",
            "Epoch 334/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3174 - accuracy: 0.8943 - val_loss: 0.4937 - val_accuracy: 0.7951\n",
            "Epoch 335/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3284 - accuracy: 0.9062 - val_loss: 0.4926 - val_accuracy: 0.7951\n",
            "Epoch 336/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3533 - accuracy: 0.8929 - val_loss: 0.4912 - val_accuracy: 0.7951\n",
            "Epoch 337/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3142 - accuracy: 0.8899 - val_loss: 0.4916 - val_accuracy: 0.7951\n",
            "Epoch 338/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3542 - accuracy: 0.8824 - val_loss: 0.4924 - val_accuracy: 0.7951\n",
            "Epoch 339/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3303 - accuracy: 0.9033 - val_loss: 0.4912 - val_accuracy: 0.7951\n",
            "Epoch 340/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3322 - accuracy: 0.8810 - val_loss: 0.4898 - val_accuracy: 0.7951\n",
            "Epoch 341/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3302 - accuracy: 0.8884 - val_loss: 0.4902 - val_accuracy: 0.7951\n",
            "Epoch 342/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3348 - accuracy: 0.8929 - val_loss: 0.4911 - val_accuracy: 0.7951\n",
            "Epoch 343/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3379 - accuracy: 0.8899 - val_loss: 0.4903 - val_accuracy: 0.7951\n",
            "Epoch 344/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3496 - accuracy: 0.8943 - val_loss: 0.4906 - val_accuracy: 0.7951\n",
            "Epoch 345/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.3148 - accuracy: 0.8943 - val_loss: 0.4907 - val_accuracy: 0.7951\n",
            "Epoch 346/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3180 - accuracy: 0.8943 - val_loss: 0.4902 - val_accuracy: 0.7951\n",
            "Epoch 347/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3275 - accuracy: 0.8765 - val_loss: 0.4904 - val_accuracy: 0.7951\n",
            "Epoch 348/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3062 - accuracy: 0.8854 - val_loss: 0.4914 - val_accuracy: 0.7951\n",
            "Epoch 349/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3102 - accuracy: 0.9018 - val_loss: 0.4903 - val_accuracy: 0.7951\n",
            "Epoch 350/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3312 - accuracy: 0.8899 - val_loss: 0.4915 - val_accuracy: 0.7951\n",
            "Epoch 351/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3431 - accuracy: 0.8929 - val_loss: 0.4911 - val_accuracy: 0.7951\n",
            "Epoch 352/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3268 - accuracy: 0.9062 - val_loss: 0.4906 - val_accuracy: 0.7951\n",
            "Epoch 353/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3109 - accuracy: 0.8958 - val_loss: 0.4908 - val_accuracy: 0.7951\n",
            "Epoch 354/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3374 - accuracy: 0.8869 - val_loss: 0.4890 - val_accuracy: 0.8056\n",
            "Epoch 355/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3075 - accuracy: 0.8973 - val_loss: 0.4878 - val_accuracy: 0.8021\n",
            "Epoch 356/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3198 - accuracy: 0.8795 - val_loss: 0.4872 - val_accuracy: 0.7986\n",
            "Epoch 357/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3274 - accuracy: 0.8690 - val_loss: 0.4861 - val_accuracy: 0.8021\n",
            "Epoch 358/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3120 - accuracy: 0.9003 - val_loss: 0.4860 - val_accuracy: 0.8056\n",
            "Epoch 359/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.3046 - accuracy: 0.9122 - val_loss: 0.4866 - val_accuracy: 0.8021\n",
            "Epoch 360/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3234 - accuracy: 0.8899 - val_loss: 0.4857 - val_accuracy: 0.8021\n",
            "Epoch 361/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3154 - accuracy: 0.8988 - val_loss: 0.4859 - val_accuracy: 0.8021\n",
            "Epoch 362/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3085 - accuracy: 0.8929 - val_loss: 0.4850 - val_accuracy: 0.8056\n",
            "Epoch 363/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3173 - accuracy: 0.9018 - val_loss: 0.4849 - val_accuracy: 0.8056\n",
            "Epoch 364/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3020 - accuracy: 0.9077 - val_loss: 0.4828 - val_accuracy: 0.8090\n",
            "Epoch 365/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3086 - accuracy: 0.9048 - val_loss: 0.4826 - val_accuracy: 0.8056\n",
            "Epoch 366/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3122 - accuracy: 0.9003 - val_loss: 0.4823 - val_accuracy: 0.8021\n",
            "Epoch 367/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2852 - accuracy: 0.9092 - val_loss: 0.4815 - val_accuracy: 0.8056\n",
            "Epoch 368/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3121 - accuracy: 0.8973 - val_loss: 0.4812 - val_accuracy: 0.8090\n",
            "Epoch 369/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3062 - accuracy: 0.8973 - val_loss: 0.4808 - val_accuracy: 0.8090\n",
            "Epoch 370/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3022 - accuracy: 0.8914 - val_loss: 0.4812 - val_accuracy: 0.8090\n",
            "Epoch 371/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2940 - accuracy: 0.9092 - val_loss: 0.4805 - val_accuracy: 0.8125\n",
            "Epoch 372/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2985 - accuracy: 0.9033 - val_loss: 0.4806 - val_accuracy: 0.8160\n",
            "Epoch 373/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2929 - accuracy: 0.9003 - val_loss: 0.4791 - val_accuracy: 0.8160\n",
            "Epoch 374/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3157 - accuracy: 0.8914 - val_loss: 0.4789 - val_accuracy: 0.8125\n",
            "Epoch 375/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3303 - accuracy: 0.8810 - val_loss: 0.4783 - val_accuracy: 0.8194\n",
            "Epoch 376/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3072 - accuracy: 0.8973 - val_loss: 0.4785 - val_accuracy: 0.8194\n",
            "Epoch 377/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3125 - accuracy: 0.8810 - val_loss: 0.4784 - val_accuracy: 0.8125\n",
            "Epoch 378/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3003 - accuracy: 0.8914 - val_loss: 0.4776 - val_accuracy: 0.8160\n",
            "Epoch 379/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2977 - accuracy: 0.9077 - val_loss: 0.4776 - val_accuracy: 0.8160\n",
            "Epoch 380/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2953 - accuracy: 0.9256 - val_loss: 0.4767 - val_accuracy: 0.8194\n",
            "Epoch 381/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2930 - accuracy: 0.9107 - val_loss: 0.4762 - val_accuracy: 0.8194\n",
            "Epoch 382/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3140 - accuracy: 0.8869 - val_loss: 0.4766 - val_accuracy: 0.8194\n",
            "Epoch 383/1000\n",
            "21/21 [==============================] - 2s 91ms/step - loss: 0.2981 - accuracy: 0.8988 - val_loss: 0.4783 - val_accuracy: 0.8194\n",
            "Epoch 384/1000\n",
            "21/21 [==============================] - 2s 89ms/step - loss: 0.2811 - accuracy: 0.8899 - val_loss: 0.4781 - val_accuracy: 0.8160\n",
            "Epoch 385/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.2993 - accuracy: 0.9077 - val_loss: 0.4782 - val_accuracy: 0.8125\n",
            "Epoch 386/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2699 - accuracy: 0.9077 - val_loss: 0.4772 - val_accuracy: 0.8160\n",
            "Epoch 387/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3057 - accuracy: 0.8958 - val_loss: 0.4769 - val_accuracy: 0.8194\n",
            "Epoch 388/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2978 - accuracy: 0.9018 - val_loss: 0.4764 - val_accuracy: 0.8160\n",
            "Epoch 389/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2879 - accuracy: 0.8943 - val_loss: 0.4762 - val_accuracy: 0.8194\n",
            "Epoch 390/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2909 - accuracy: 0.9077 - val_loss: 0.4763 - val_accuracy: 0.8194\n",
            "Epoch 391/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2898 - accuracy: 0.9271 - val_loss: 0.4771 - val_accuracy: 0.8160\n",
            "Epoch 392/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3108 - accuracy: 0.8973 - val_loss: 0.4767 - val_accuracy: 0.8160\n",
            "Epoch 393/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3161 - accuracy: 0.8943 - val_loss: 0.4761 - val_accuracy: 0.8160\n",
            "Epoch 394/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3013 - accuracy: 0.8839 - val_loss: 0.4767 - val_accuracy: 0.8160\n",
            "Epoch 395/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.3007 - accuracy: 0.8914 - val_loss: 0.4758 - val_accuracy: 0.8160\n",
            "Epoch 396/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.3034 - accuracy: 0.8914 - val_loss: 0.4755 - val_accuracy: 0.8194\n",
            "Epoch 397/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.3002 - accuracy: 0.9003 - val_loss: 0.4746 - val_accuracy: 0.8194\n",
            "Epoch 398/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2820 - accuracy: 0.9137 - val_loss: 0.4738 - val_accuracy: 0.8160\n",
            "Epoch 399/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2846 - accuracy: 0.8929 - val_loss: 0.4734 - val_accuracy: 0.8229\n",
            "Epoch 400/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2948 - accuracy: 0.9033 - val_loss: 0.4723 - val_accuracy: 0.8194\n",
            "Epoch 401/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2915 - accuracy: 0.8988 - val_loss: 0.4727 - val_accuracy: 0.8264\n",
            "Epoch 402/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2764 - accuracy: 0.9152 - val_loss: 0.4731 - val_accuracy: 0.8229\n",
            "Epoch 403/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2973 - accuracy: 0.8973 - val_loss: 0.4716 - val_accuracy: 0.8264\n",
            "Epoch 404/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2820 - accuracy: 0.9152 - val_loss: 0.4718 - val_accuracy: 0.8229\n",
            "Epoch 405/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2847 - accuracy: 0.8943 - val_loss: 0.4706 - val_accuracy: 0.8264\n",
            "Epoch 406/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2857 - accuracy: 0.9018 - val_loss: 0.4705 - val_accuracy: 0.8264\n",
            "Epoch 407/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2889 - accuracy: 0.8854 - val_loss: 0.4695 - val_accuracy: 0.8229\n",
            "Epoch 408/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2994 - accuracy: 0.8973 - val_loss: 0.4703 - val_accuracy: 0.8229\n",
            "Epoch 409/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2853 - accuracy: 0.8973 - val_loss: 0.4693 - val_accuracy: 0.8264\n",
            "Epoch 410/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2981 - accuracy: 0.8973 - val_loss: 0.4703 - val_accuracy: 0.8264\n",
            "Epoch 411/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2733 - accuracy: 0.9271 - val_loss: 0.4700 - val_accuracy: 0.8229\n",
            "Epoch 412/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2661 - accuracy: 0.9196 - val_loss: 0.4706 - val_accuracy: 0.8229\n",
            "Epoch 413/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2857 - accuracy: 0.8854 - val_loss: 0.4705 - val_accuracy: 0.8229\n",
            "Epoch 414/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2904 - accuracy: 0.9092 - val_loss: 0.4714 - val_accuracy: 0.8229\n",
            "Epoch 415/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2859 - accuracy: 0.8988 - val_loss: 0.4707 - val_accuracy: 0.8264\n",
            "Epoch 416/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2952 - accuracy: 0.9107 - val_loss: 0.4709 - val_accuracy: 0.8264\n",
            "Epoch 417/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2973 - accuracy: 0.9062 - val_loss: 0.4699 - val_accuracy: 0.8264\n",
            "Epoch 418/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2845 - accuracy: 0.9033 - val_loss: 0.4700 - val_accuracy: 0.8264\n",
            "Epoch 419/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2772 - accuracy: 0.9122 - val_loss: 0.4701 - val_accuracy: 0.8264\n",
            "Epoch 420/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2957 - accuracy: 0.8914 - val_loss: 0.4710 - val_accuracy: 0.8264\n",
            "Epoch 421/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2976 - accuracy: 0.9033 - val_loss: 0.4703 - val_accuracy: 0.8229\n",
            "Epoch 422/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2603 - accuracy: 0.9286 - val_loss: 0.4709 - val_accuracy: 0.8229\n",
            "Epoch 423/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2785 - accuracy: 0.9092 - val_loss: 0.4704 - val_accuracy: 0.8264\n",
            "Epoch 424/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2786 - accuracy: 0.9137 - val_loss: 0.4696 - val_accuracy: 0.8299\n",
            "Epoch 425/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2550 - accuracy: 0.9241 - val_loss: 0.4691 - val_accuracy: 0.8264\n",
            "Epoch 426/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2790 - accuracy: 0.9092 - val_loss: 0.4684 - val_accuracy: 0.8264\n",
            "Epoch 427/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2802 - accuracy: 0.9211 - val_loss: 0.4675 - val_accuracy: 0.8299\n",
            "Epoch 428/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2601 - accuracy: 0.9241 - val_loss: 0.4677 - val_accuracy: 0.8299\n",
            "Epoch 429/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2587 - accuracy: 0.9241 - val_loss: 0.4674 - val_accuracy: 0.8299\n",
            "Epoch 430/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2621 - accuracy: 0.9301 - val_loss: 0.4667 - val_accuracy: 0.8333\n",
            "Epoch 431/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2698 - accuracy: 0.9092 - val_loss: 0.4655 - val_accuracy: 0.8299\n",
            "Epoch 432/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2715 - accuracy: 0.9077 - val_loss: 0.4650 - val_accuracy: 0.8333\n",
            "Epoch 433/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2707 - accuracy: 0.9048 - val_loss: 0.4652 - val_accuracy: 0.8299\n",
            "Epoch 434/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2741 - accuracy: 0.9182 - val_loss: 0.4641 - val_accuracy: 0.8368\n",
            "Epoch 435/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2719 - accuracy: 0.9048 - val_loss: 0.4640 - val_accuracy: 0.8368\n",
            "Epoch 436/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.2661 - accuracy: 0.9092 - val_loss: 0.4641 - val_accuracy: 0.8333\n",
            "Epoch 437/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2801 - accuracy: 0.9062 - val_loss: 0.4633 - val_accuracy: 0.8333\n",
            "Epoch 438/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2683 - accuracy: 0.9092 - val_loss: 0.4632 - val_accuracy: 0.8264\n",
            "Epoch 439/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2888 - accuracy: 0.9107 - val_loss: 0.4624 - val_accuracy: 0.8299\n",
            "Epoch 440/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2743 - accuracy: 0.9167 - val_loss: 0.4623 - val_accuracy: 0.8299\n",
            "Epoch 441/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2663 - accuracy: 0.8958 - val_loss: 0.4618 - val_accuracy: 0.8333\n",
            "Epoch 442/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2453 - accuracy: 0.9122 - val_loss: 0.4619 - val_accuracy: 0.8299\n",
            "Epoch 443/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2532 - accuracy: 0.9211 - val_loss: 0.4611 - val_accuracy: 0.8333\n",
            "Epoch 444/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2650 - accuracy: 0.9196 - val_loss: 0.4623 - val_accuracy: 0.8299\n",
            "Epoch 445/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2662 - accuracy: 0.9122 - val_loss: 0.4630 - val_accuracy: 0.8299\n",
            "Epoch 446/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2585 - accuracy: 0.9211 - val_loss: 0.4627 - val_accuracy: 0.8333\n",
            "Epoch 447/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2716 - accuracy: 0.8958 - val_loss: 0.4637 - val_accuracy: 0.8299\n",
            "Epoch 448/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2671 - accuracy: 0.9211 - val_loss: 0.4630 - val_accuracy: 0.8299\n",
            "Epoch 449/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2529 - accuracy: 0.9286 - val_loss: 0.4627 - val_accuracy: 0.8333\n",
            "Epoch 450/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2490 - accuracy: 0.9241 - val_loss: 0.4626 - val_accuracy: 0.8333\n",
            "Epoch 451/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2639 - accuracy: 0.9182 - val_loss: 0.4630 - val_accuracy: 0.8299\n",
            "Epoch 452/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2382 - accuracy: 0.9226 - val_loss: 0.4634 - val_accuracy: 0.8299\n",
            "Epoch 453/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2572 - accuracy: 0.9226 - val_loss: 0.4627 - val_accuracy: 0.8299\n",
            "Epoch 454/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2627 - accuracy: 0.9152 - val_loss: 0.4623 - val_accuracy: 0.8299\n",
            "Epoch 455/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2665 - accuracy: 0.9003 - val_loss: 0.4623 - val_accuracy: 0.8299\n",
            "Epoch 456/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2553 - accuracy: 0.9196 - val_loss: 0.4634 - val_accuracy: 0.8299\n",
            "Epoch 457/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2555 - accuracy: 0.9286 - val_loss: 0.4626 - val_accuracy: 0.8299\n",
            "Epoch 458/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2600 - accuracy: 0.9182 - val_loss: 0.4604 - val_accuracy: 0.8299\n",
            "Epoch 459/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2480 - accuracy: 0.9286 - val_loss: 0.4596 - val_accuracy: 0.8299\n",
            "Epoch 460/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2787 - accuracy: 0.9048 - val_loss: 0.4598 - val_accuracy: 0.8264\n",
            "Epoch 461/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2533 - accuracy: 0.9033 - val_loss: 0.4599 - val_accuracy: 0.8333\n",
            "Epoch 462/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2665 - accuracy: 0.9226 - val_loss: 0.4593 - val_accuracy: 0.8264\n",
            "Epoch 463/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2507 - accuracy: 0.9211 - val_loss: 0.4595 - val_accuracy: 0.8299\n",
            "Epoch 464/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2534 - accuracy: 0.9211 - val_loss: 0.4599 - val_accuracy: 0.8299\n",
            "Epoch 465/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2605 - accuracy: 0.8988 - val_loss: 0.4595 - val_accuracy: 0.8264\n",
            "Epoch 466/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2702 - accuracy: 0.9122 - val_loss: 0.4589 - val_accuracy: 0.8264\n",
            "Epoch 467/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2571 - accuracy: 0.9167 - val_loss: 0.4583 - val_accuracy: 0.8333\n",
            "Epoch 468/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2517 - accuracy: 0.9226 - val_loss: 0.4584 - val_accuracy: 0.8299\n",
            "Epoch 469/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2532 - accuracy: 0.9122 - val_loss: 0.4568 - val_accuracy: 0.8333\n",
            "Epoch 470/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2475 - accuracy: 0.9167 - val_loss: 0.4571 - val_accuracy: 0.8299\n",
            "Epoch 471/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2655 - accuracy: 0.9122 - val_loss: 0.4572 - val_accuracy: 0.8333\n",
            "Epoch 472/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2291 - accuracy: 0.9182 - val_loss: 0.4571 - val_accuracy: 0.8299\n",
            "Epoch 473/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2473 - accuracy: 0.9137 - val_loss: 0.4576 - val_accuracy: 0.8368\n",
            "Epoch 474/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2434 - accuracy: 0.9226 - val_loss: 0.4576 - val_accuracy: 0.8299\n",
            "Epoch 475/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2250 - accuracy: 0.9286 - val_loss: 0.4579 - val_accuracy: 0.8333\n",
            "Epoch 476/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2407 - accuracy: 0.9286 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
            "Epoch 477/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2508 - accuracy: 0.9167 - val_loss: 0.4600 - val_accuracy: 0.8299\n",
            "Epoch 478/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2350 - accuracy: 0.9271 - val_loss: 0.4591 - val_accuracy: 0.8333\n",
            "Epoch 479/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2348 - accuracy: 0.9271 - val_loss: 0.4607 - val_accuracy: 0.8368\n",
            "Epoch 480/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2488 - accuracy: 0.9152 - val_loss: 0.4618 - val_accuracy: 0.8368\n",
            "Epoch 481/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2568 - accuracy: 0.9226 - val_loss: 0.4612 - val_accuracy: 0.8333\n",
            "Epoch 482/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2456 - accuracy: 0.9167 - val_loss: 0.4626 - val_accuracy: 0.8299\n",
            "Epoch 483/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2660 - accuracy: 0.8973 - val_loss: 0.4624 - val_accuracy: 0.8299\n",
            "Epoch 484/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2549 - accuracy: 0.9286 - val_loss: 0.4616 - val_accuracy: 0.8299\n",
            "Epoch 485/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2494 - accuracy: 0.9137 - val_loss: 0.4609 - val_accuracy: 0.8368\n",
            "Epoch 486/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2601 - accuracy: 0.8988 - val_loss: 0.4603 - val_accuracy: 0.8368\n",
            "Epoch 487/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2339 - accuracy: 0.9271 - val_loss: 0.4599 - val_accuracy: 0.8333\n",
            "Epoch 488/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2491 - accuracy: 0.9241 - val_loss: 0.4596 - val_accuracy: 0.8333\n",
            "Epoch 489/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2578 - accuracy: 0.9211 - val_loss: 0.4597 - val_accuracy: 0.8299\n",
            "Epoch 490/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2365 - accuracy: 0.9152 - val_loss: 0.4595 - val_accuracy: 0.8299\n",
            "Epoch 491/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2675 - accuracy: 0.9003 - val_loss: 0.4599 - val_accuracy: 0.8264\n",
            "Epoch 492/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2477 - accuracy: 0.9107 - val_loss: 0.4580 - val_accuracy: 0.8299\n",
            "Epoch 493/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2447 - accuracy: 0.9196 - val_loss: 0.4566 - val_accuracy: 0.8333\n",
            "Epoch 494/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.2435 - accuracy: 0.9196 - val_loss: 0.4584 - val_accuracy: 0.8299\n",
            "Epoch 495/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.2626 - accuracy: 0.9077 - val_loss: 0.4577 - val_accuracy: 0.8299\n",
            "Epoch 496/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2271 - accuracy: 0.9256 - val_loss: 0.4582 - val_accuracy: 0.8333\n",
            "Epoch 497/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2560 - accuracy: 0.9048 - val_loss: 0.4572 - val_accuracy: 0.8333\n",
            "Epoch 498/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2446 - accuracy: 0.9241 - val_loss: 0.4566 - val_accuracy: 0.8333\n",
            "Epoch 499/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2425 - accuracy: 0.9315 - val_loss: 0.4564 - val_accuracy: 0.8333\n",
            "Epoch 500/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2274 - accuracy: 0.9360 - val_loss: 0.4549 - val_accuracy: 0.8333\n",
            "Epoch 501/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2420 - accuracy: 0.9330 - val_loss: 0.4553 - val_accuracy: 0.8333\n",
            "Epoch 502/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2537 - accuracy: 0.9241 - val_loss: 0.4550 - val_accuracy: 0.8333\n",
            "Epoch 503/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2490 - accuracy: 0.9182 - val_loss: 0.4548 - val_accuracy: 0.8333\n",
            "Epoch 504/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2332 - accuracy: 0.9241 - val_loss: 0.4549 - val_accuracy: 0.8299\n",
            "Epoch 505/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2523 - accuracy: 0.9122 - val_loss: 0.4543 - val_accuracy: 0.8264\n",
            "Epoch 506/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2518 - accuracy: 0.9062 - val_loss: 0.4531 - val_accuracy: 0.8264\n",
            "Epoch 507/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2435 - accuracy: 0.9182 - val_loss: 0.4530 - val_accuracy: 0.8264\n",
            "Epoch 508/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2357 - accuracy: 0.9167 - val_loss: 0.4515 - val_accuracy: 0.8264\n",
            "Epoch 509/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2461 - accuracy: 0.9137 - val_loss: 0.4511 - val_accuracy: 0.8299\n",
            "Epoch 510/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2283 - accuracy: 0.9286 - val_loss: 0.4516 - val_accuracy: 0.8264\n",
            "Epoch 511/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2431 - accuracy: 0.9152 - val_loss: 0.4517 - val_accuracy: 0.8264\n",
            "Epoch 512/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2390 - accuracy: 0.9241 - val_loss: 0.4521 - val_accuracy: 0.8264\n",
            "Epoch 513/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2503 - accuracy: 0.9152 - val_loss: 0.4516 - val_accuracy: 0.8264\n",
            "Epoch 514/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2226 - accuracy: 0.9271 - val_loss: 0.4520 - val_accuracy: 0.8264\n",
            "Epoch 515/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2318 - accuracy: 0.9092 - val_loss: 0.4521 - val_accuracy: 0.8299\n",
            "Epoch 516/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2353 - accuracy: 0.9360 - val_loss: 0.4517 - val_accuracy: 0.8264\n",
            "Epoch 517/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2358 - accuracy: 0.9241 - val_loss: 0.4527 - val_accuracy: 0.8264\n",
            "Epoch 518/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2412 - accuracy: 0.9137 - val_loss: 0.4525 - val_accuracy: 0.8264\n",
            "Epoch 519/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2357 - accuracy: 0.9152 - val_loss: 0.4525 - val_accuracy: 0.8264\n",
            "Epoch 520/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2512 - accuracy: 0.8973 - val_loss: 0.4523 - val_accuracy: 0.8299\n",
            "Epoch 521/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2383 - accuracy: 0.9137 - val_loss: 0.4517 - val_accuracy: 0.8299\n",
            "Epoch 522/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2540 - accuracy: 0.9137 - val_loss: 0.4513 - val_accuracy: 0.8299\n",
            "Epoch 523/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2319 - accuracy: 0.9271 - val_loss: 0.4509 - val_accuracy: 0.8368\n",
            "Epoch 524/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2559 - accuracy: 0.9092 - val_loss: 0.4499 - val_accuracy: 0.8299\n",
            "Epoch 525/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2419 - accuracy: 0.9152 - val_loss: 0.4498 - val_accuracy: 0.8264\n",
            "Epoch 526/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2170 - accuracy: 0.9375 - val_loss: 0.4489 - val_accuracy: 0.8264\n",
            "Epoch 527/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2347 - accuracy: 0.9256 - val_loss: 0.4493 - val_accuracy: 0.8264\n",
            "Epoch 528/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2302 - accuracy: 0.9315 - val_loss: 0.4489 - val_accuracy: 0.8264\n",
            "Epoch 529/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2296 - accuracy: 0.9271 - val_loss: 0.4481 - val_accuracy: 0.8264\n",
            "Epoch 530/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2208 - accuracy: 0.9375 - val_loss: 0.4471 - val_accuracy: 0.8299\n",
            "Epoch 531/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2431 - accuracy: 0.9301 - val_loss: 0.4468 - val_accuracy: 0.8299\n",
            "Epoch 532/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2304 - accuracy: 0.9152 - val_loss: 0.4477 - val_accuracy: 0.8299\n",
            "Epoch 533/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.2213 - accuracy: 0.9360 - val_loss: 0.4474 - val_accuracy: 0.8299\n",
            "Epoch 534/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.2295 - accuracy: 0.9256 - val_loss: 0.4475 - val_accuracy: 0.8299\n",
            "Epoch 535/1000\n",
            "21/21 [==============================] - 2s 81ms/step - loss: 0.2226 - accuracy: 0.9286 - val_loss: 0.4485 - val_accuracy: 0.8264\n",
            "Epoch 536/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2386 - accuracy: 0.9182 - val_loss: 0.4488 - val_accuracy: 0.8264\n",
            "Epoch 537/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2259 - accuracy: 0.9182 - val_loss: 0.4490 - val_accuracy: 0.8333\n",
            "Epoch 538/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2322 - accuracy: 0.9092 - val_loss: 0.4477 - val_accuracy: 0.8333\n",
            "Epoch 539/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2144 - accuracy: 0.9315 - val_loss: 0.4478 - val_accuracy: 0.8299\n",
            "Epoch 540/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2179 - accuracy: 0.9345 - val_loss: 0.4490 - val_accuracy: 0.8299\n",
            "Epoch 541/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2412 - accuracy: 0.9196 - val_loss: 0.4485 - val_accuracy: 0.8264\n",
            "Epoch 542/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2241 - accuracy: 0.9226 - val_loss: 0.4485 - val_accuracy: 0.8299\n",
            "Epoch 543/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2334 - accuracy: 0.9271 - val_loss: 0.4486 - val_accuracy: 0.8299\n",
            "Epoch 544/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2410 - accuracy: 0.9048 - val_loss: 0.4478 - val_accuracy: 0.8299\n",
            "Epoch 545/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2294 - accuracy: 0.9241 - val_loss: 0.4467 - val_accuracy: 0.8333\n",
            "Epoch 546/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2518 - accuracy: 0.9018 - val_loss: 0.4458 - val_accuracy: 0.8333\n",
            "Epoch 547/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2158 - accuracy: 0.9405 - val_loss: 0.4429 - val_accuracy: 0.8333\n",
            "Epoch 548/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2176 - accuracy: 0.9301 - val_loss: 0.4424 - val_accuracy: 0.8333\n",
            "Epoch 549/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2178 - accuracy: 0.9271 - val_loss: 0.4409 - val_accuracy: 0.8333\n",
            "Epoch 550/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2253 - accuracy: 0.9330 - val_loss: 0.4415 - val_accuracy: 0.8368\n",
            "Epoch 551/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2362 - accuracy: 0.9226 - val_loss: 0.4408 - val_accuracy: 0.8368\n",
            "Epoch 552/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2592 - accuracy: 0.9077 - val_loss: 0.4421 - val_accuracy: 0.8368\n",
            "Epoch 553/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2406 - accuracy: 0.9107 - val_loss: 0.4416 - val_accuracy: 0.8368\n",
            "Epoch 554/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2038 - accuracy: 0.9390 - val_loss: 0.4437 - val_accuracy: 0.8368\n",
            "Epoch 555/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2231 - accuracy: 0.9271 - val_loss: 0.4444 - val_accuracy: 0.8368\n",
            "Epoch 556/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1983 - accuracy: 0.9271 - val_loss: 0.4445 - val_accuracy: 0.8368\n",
            "Epoch 557/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.2482 - accuracy: 0.9077 - val_loss: 0.4439 - val_accuracy: 0.8368\n",
            "Epoch 558/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2565 - accuracy: 0.9107 - val_loss: 0.4452 - val_accuracy: 0.8368\n",
            "Epoch 559/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.2109 - accuracy: 0.9360 - val_loss: 0.4456 - val_accuracy: 0.8368\n",
            "Epoch 560/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2218 - accuracy: 0.9271 - val_loss: 0.4456 - val_accuracy: 0.8368\n",
            "Epoch 561/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.2227 - accuracy: 0.9152 - val_loss: 0.4455 - val_accuracy: 0.8368\n",
            "Epoch 562/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2330 - accuracy: 0.9167 - val_loss: 0.4426 - val_accuracy: 0.8403\n",
            "Epoch 563/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2300 - accuracy: 0.9241 - val_loss: 0.4429 - val_accuracy: 0.8403\n",
            "Epoch 564/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2480 - accuracy: 0.9003 - val_loss: 0.4426 - val_accuracy: 0.8403\n",
            "Epoch 565/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2134 - accuracy: 0.9226 - val_loss: 0.4415 - val_accuracy: 0.8438\n",
            "Epoch 566/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2210 - accuracy: 0.9315 - val_loss: 0.4427 - val_accuracy: 0.8438\n",
            "Epoch 567/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2200 - accuracy: 0.9241 - val_loss: 0.4426 - val_accuracy: 0.8403\n",
            "Epoch 568/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2242 - accuracy: 0.9226 - val_loss: 0.4441 - val_accuracy: 0.8403\n",
            "Epoch 569/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2082 - accuracy: 0.9360 - val_loss: 0.4426 - val_accuracy: 0.8403\n",
            "Epoch 570/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2163 - accuracy: 0.9211 - val_loss: 0.4422 - val_accuracy: 0.8368\n",
            "Epoch 571/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2128 - accuracy: 0.9271 - val_loss: 0.4420 - val_accuracy: 0.8368\n",
            "Epoch 572/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2105 - accuracy: 0.9315 - val_loss: 0.4435 - val_accuracy: 0.8368\n",
            "Epoch 573/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2269 - accuracy: 0.9241 - val_loss: 0.4431 - val_accuracy: 0.8368\n",
            "Epoch 574/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2190 - accuracy: 0.9167 - val_loss: 0.4439 - val_accuracy: 0.8368\n",
            "Epoch 575/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2053 - accuracy: 0.9375 - val_loss: 0.4463 - val_accuracy: 0.8368\n",
            "Epoch 576/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.2230 - accuracy: 0.9182 - val_loss: 0.4463 - val_accuracy: 0.8333\n",
            "Epoch 577/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2171 - accuracy: 0.9182 - val_loss: 0.4445 - val_accuracy: 0.8403\n",
            "Epoch 578/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2066 - accuracy: 0.9226 - val_loss: 0.4433 - val_accuracy: 0.8403\n",
            "Epoch 579/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2399 - accuracy: 0.9211 - val_loss: 0.4419 - val_accuracy: 0.8403\n",
            "Epoch 580/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2184 - accuracy: 0.9182 - val_loss: 0.4409 - val_accuracy: 0.8403\n",
            "Epoch 581/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.2124 - accuracy: 0.9390 - val_loss: 0.4420 - val_accuracy: 0.8403\n",
            "Epoch 582/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2188 - accuracy: 0.9137 - val_loss: 0.4447 - val_accuracy: 0.8403\n",
            "Epoch 583/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2313 - accuracy: 0.9241 - val_loss: 0.4440 - val_accuracy: 0.8368\n",
            "Epoch 584/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2201 - accuracy: 0.9241 - val_loss: 0.4464 - val_accuracy: 0.8333\n",
            "Epoch 585/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2123 - accuracy: 0.9256 - val_loss: 0.4466 - val_accuracy: 0.8299\n",
            "Epoch 586/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2063 - accuracy: 0.9301 - val_loss: 0.4457 - val_accuracy: 0.8333\n",
            "Epoch 587/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2065 - accuracy: 0.9286 - val_loss: 0.4462 - val_accuracy: 0.8333\n",
            "Epoch 588/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2210 - accuracy: 0.9226 - val_loss: 0.4457 - val_accuracy: 0.8368\n",
            "Epoch 589/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2384 - accuracy: 0.9182 - val_loss: 0.4445 - val_accuracy: 0.8333\n",
            "Epoch 590/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2264 - accuracy: 0.9256 - val_loss: 0.4430 - val_accuracy: 0.8403\n",
            "Epoch 591/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2219 - accuracy: 0.9286 - val_loss: 0.4428 - val_accuracy: 0.8333\n",
            "Epoch 592/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2104 - accuracy: 0.9286 - val_loss: 0.4437 - val_accuracy: 0.8333\n",
            "Epoch 593/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2090 - accuracy: 0.9330 - val_loss: 0.4434 - val_accuracy: 0.8368\n",
            "Epoch 594/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2045 - accuracy: 0.9375 - val_loss: 0.4444 - val_accuracy: 0.8368\n",
            "Epoch 595/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2216 - accuracy: 0.9226 - val_loss: 0.4439 - val_accuracy: 0.8403\n",
            "Epoch 596/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2164 - accuracy: 0.9330 - val_loss: 0.4442 - val_accuracy: 0.8403\n",
            "Epoch 597/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2203 - accuracy: 0.9196 - val_loss: 0.4451 - val_accuracy: 0.8368\n",
            "Epoch 598/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1885 - accuracy: 0.9330 - val_loss: 0.4459 - val_accuracy: 0.8403\n",
            "Epoch 599/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2355 - accuracy: 0.9182 - val_loss: 0.4462 - val_accuracy: 0.8438\n",
            "Epoch 600/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2363 - accuracy: 0.9211 - val_loss: 0.4467 - val_accuracy: 0.8438\n",
            "Epoch 601/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2141 - accuracy: 0.9345 - val_loss: 0.4456 - val_accuracy: 0.8403\n",
            "Epoch 602/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2295 - accuracy: 0.9048 - val_loss: 0.4450 - val_accuracy: 0.8403\n",
            "Epoch 603/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2169 - accuracy: 0.9182 - val_loss: 0.4463 - val_accuracy: 0.8438\n",
            "Epoch 604/1000\n",
            "21/21 [==============================] - 2s 89ms/step - loss: 0.2006 - accuracy: 0.9315 - val_loss: 0.4483 - val_accuracy: 0.8403\n",
            "Epoch 605/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.2034 - accuracy: 0.9211 - val_loss: 0.4484 - val_accuracy: 0.8403\n",
            "Epoch 606/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2070 - accuracy: 0.9301 - val_loss: 0.4476 - val_accuracy: 0.8403\n",
            "Epoch 607/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1930 - accuracy: 0.9315 - val_loss: 0.4464 - val_accuracy: 0.8403\n",
            "Epoch 608/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2316 - accuracy: 0.9122 - val_loss: 0.4453 - val_accuracy: 0.8438\n",
            "Epoch 609/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1980 - accuracy: 0.9479 - val_loss: 0.4447 - val_accuracy: 0.8438\n",
            "Epoch 610/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2185 - accuracy: 0.9226 - val_loss: 0.4439 - val_accuracy: 0.8368\n",
            "Epoch 611/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2083 - accuracy: 0.9182 - val_loss: 0.4433 - val_accuracy: 0.8403\n",
            "Epoch 612/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2095 - accuracy: 0.9226 - val_loss: 0.4427 - val_accuracy: 0.8438\n",
            "Epoch 613/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2296 - accuracy: 0.9241 - val_loss: 0.4438 - val_accuracy: 0.8438\n",
            "Epoch 614/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2029 - accuracy: 0.9360 - val_loss: 0.4435 - val_accuracy: 0.8438\n",
            "Epoch 615/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2380 - accuracy: 0.9092 - val_loss: 0.4432 - val_accuracy: 0.8472\n",
            "Epoch 616/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2181 - accuracy: 0.9211 - val_loss: 0.4430 - val_accuracy: 0.8472\n",
            "Epoch 617/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2012 - accuracy: 0.9330 - val_loss: 0.4418 - val_accuracy: 0.8472\n",
            "Epoch 618/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2157 - accuracy: 0.9256 - val_loss: 0.4431 - val_accuracy: 0.8438\n",
            "Epoch 619/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2189 - accuracy: 0.9182 - val_loss: 0.4437 - val_accuracy: 0.8438\n",
            "Epoch 620/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.2148 - accuracy: 0.9182 - val_loss: 0.4439 - val_accuracy: 0.8403\n",
            "Epoch 621/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1960 - accuracy: 0.9479 - val_loss: 0.4428 - val_accuracy: 0.8472\n",
            "Epoch 622/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2290 - accuracy: 0.9196 - val_loss: 0.4438 - val_accuracy: 0.8472\n",
            "Epoch 623/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2093 - accuracy: 0.9330 - val_loss: 0.4436 - val_accuracy: 0.8472\n",
            "Epoch 624/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2107 - accuracy: 0.9256 - val_loss: 0.4434 - val_accuracy: 0.8438\n",
            "Epoch 625/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2061 - accuracy: 0.9301 - val_loss: 0.4437 - val_accuracy: 0.8438\n",
            "Epoch 626/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2444 - accuracy: 0.9167 - val_loss: 0.4415 - val_accuracy: 0.8472\n",
            "Epoch 627/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2005 - accuracy: 0.9330 - val_loss: 0.4423 - val_accuracy: 0.8472\n",
            "Epoch 628/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1921 - accuracy: 0.9449 - val_loss: 0.4411 - val_accuracy: 0.8472\n",
            "Epoch 629/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1907 - accuracy: 0.9420 - val_loss: 0.4414 - val_accuracy: 0.8472\n",
            "Epoch 630/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2205 - accuracy: 0.9122 - val_loss: 0.4411 - val_accuracy: 0.8438\n",
            "Epoch 631/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2133 - accuracy: 0.9226 - val_loss: 0.4437 - val_accuracy: 0.8438\n",
            "Epoch 632/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2020 - accuracy: 0.9256 - val_loss: 0.4435 - val_accuracy: 0.8438\n",
            "Epoch 633/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2042 - accuracy: 0.9226 - val_loss: 0.4448 - val_accuracy: 0.8403\n",
            "Epoch 634/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2238 - accuracy: 0.9107 - val_loss: 0.4450 - val_accuracy: 0.8368\n",
            "Epoch 635/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2087 - accuracy: 0.9286 - val_loss: 0.4458 - val_accuracy: 0.8368\n",
            "Epoch 636/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2009 - accuracy: 0.9241 - val_loss: 0.4452 - val_accuracy: 0.8403\n",
            "Epoch 637/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2043 - accuracy: 0.9286 - val_loss: 0.4433 - val_accuracy: 0.8472\n",
            "Epoch 638/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2219 - accuracy: 0.9241 - val_loss: 0.4440 - val_accuracy: 0.8438\n",
            "Epoch 639/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1931 - accuracy: 0.9464 - val_loss: 0.4436 - val_accuracy: 0.8438\n",
            "Epoch 640/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2294 - accuracy: 0.9196 - val_loss: 0.4435 - val_accuracy: 0.8438\n",
            "Epoch 641/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1957 - accuracy: 0.9286 - val_loss: 0.4414 - val_accuracy: 0.8438\n",
            "Epoch 642/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2003 - accuracy: 0.9196 - val_loss: 0.4401 - val_accuracy: 0.8438\n",
            "Epoch 643/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2193 - accuracy: 0.9256 - val_loss: 0.4401 - val_accuracy: 0.8472\n",
            "Epoch 644/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2379 - accuracy: 0.9137 - val_loss: 0.4416 - val_accuracy: 0.8472\n",
            "Epoch 645/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2097 - accuracy: 0.9137 - val_loss: 0.4451 - val_accuracy: 0.8438\n",
            "Epoch 646/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2031 - accuracy: 0.9256 - val_loss: 0.4447 - val_accuracy: 0.8472\n",
            "Epoch 647/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2271 - accuracy: 0.9241 - val_loss: 0.4442 - val_accuracy: 0.8507\n",
            "Epoch 648/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2101 - accuracy: 0.9226 - val_loss: 0.4448 - val_accuracy: 0.8507\n",
            "Epoch 649/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1886 - accuracy: 0.9449 - val_loss: 0.4444 - val_accuracy: 0.8472\n",
            "Epoch 650/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1993 - accuracy: 0.9271 - val_loss: 0.4453 - val_accuracy: 0.8472\n",
            "Epoch 651/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2054 - accuracy: 0.9241 - val_loss: 0.4440 - val_accuracy: 0.8507\n",
            "Epoch 652/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2233 - accuracy: 0.9122 - val_loss: 0.4445 - val_accuracy: 0.8507\n",
            "Epoch 653/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2068 - accuracy: 0.9301 - val_loss: 0.4449 - val_accuracy: 0.8542\n",
            "Epoch 654/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1974 - accuracy: 0.9241 - val_loss: 0.4442 - val_accuracy: 0.8507\n",
            "Epoch 655/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1928 - accuracy: 0.9315 - val_loss: 0.4440 - val_accuracy: 0.8507\n",
            "Epoch 656/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2194 - accuracy: 0.9375 - val_loss: 0.4452 - val_accuracy: 0.8507\n",
            "Epoch 657/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2167 - accuracy: 0.9375 - val_loss: 0.4442 - val_accuracy: 0.8507\n",
            "Epoch 658/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2180 - accuracy: 0.9167 - val_loss: 0.4443 - val_accuracy: 0.8507\n",
            "Epoch 659/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1787 - accuracy: 0.9449 - val_loss: 0.4420 - val_accuracy: 0.8507\n",
            "Epoch 660/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2065 - accuracy: 0.9286 - val_loss: 0.4410 - val_accuracy: 0.8507\n",
            "Epoch 661/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1967 - accuracy: 0.9330 - val_loss: 0.4420 - val_accuracy: 0.8542\n",
            "Epoch 662/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1684 - accuracy: 0.9435 - val_loss: 0.4407 - val_accuracy: 0.8507\n",
            "Epoch 663/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2064 - accuracy: 0.9271 - val_loss: 0.4415 - val_accuracy: 0.8507\n",
            "Epoch 664/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2050 - accuracy: 0.9256 - val_loss: 0.4405 - val_accuracy: 0.8507\n",
            "Epoch 665/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1939 - accuracy: 0.9494 - val_loss: 0.4418 - val_accuracy: 0.8507\n",
            "Epoch 666/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1920 - accuracy: 0.9390 - val_loss: 0.4415 - val_accuracy: 0.8542\n",
            "Epoch 667/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1894 - accuracy: 0.9405 - val_loss: 0.4418 - val_accuracy: 0.8507\n",
            "Epoch 668/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2214 - accuracy: 0.9152 - val_loss: 0.4418 - val_accuracy: 0.8542\n",
            "Epoch 669/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1978 - accuracy: 0.9241 - val_loss: 0.4410 - val_accuracy: 0.8542\n",
            "Epoch 670/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2018 - accuracy: 0.9375 - val_loss: 0.4399 - val_accuracy: 0.8542\n",
            "Epoch 671/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1927 - accuracy: 0.9301 - val_loss: 0.4419 - val_accuracy: 0.8542\n",
            "Epoch 672/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2005 - accuracy: 0.9345 - val_loss: 0.4425 - val_accuracy: 0.8542\n",
            "Epoch 673/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2032 - accuracy: 0.9390 - val_loss: 0.4432 - val_accuracy: 0.8542\n",
            "Epoch 674/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1914 - accuracy: 0.9494 - val_loss: 0.4438 - val_accuracy: 0.8542\n",
            "Epoch 675/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1821 - accuracy: 0.9449 - val_loss: 0.4449 - val_accuracy: 0.8542\n",
            "Epoch 676/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2016 - accuracy: 0.9286 - val_loss: 0.4445 - val_accuracy: 0.8542\n",
            "Epoch 677/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2019 - accuracy: 0.9256 - val_loss: 0.4429 - val_accuracy: 0.8542\n",
            "Epoch 678/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2021 - accuracy: 0.9211 - val_loss: 0.4408 - val_accuracy: 0.8542\n",
            "Epoch 679/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2031 - accuracy: 0.9241 - val_loss: 0.4422 - val_accuracy: 0.8542\n",
            "Epoch 680/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1834 - accuracy: 0.9330 - val_loss: 0.4400 - val_accuracy: 0.8542\n",
            "Epoch 681/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1572 - accuracy: 0.9643 - val_loss: 0.4389 - val_accuracy: 0.8542\n",
            "Epoch 682/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2064 - accuracy: 0.9315 - val_loss: 0.4390 - val_accuracy: 0.8542\n",
            "Epoch 683/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.2156 - accuracy: 0.9375 - val_loss: 0.4395 - val_accuracy: 0.8542\n",
            "Epoch 684/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2093 - accuracy: 0.9301 - val_loss: 0.4388 - val_accuracy: 0.8542\n",
            "Epoch 685/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2011 - accuracy: 0.9301 - val_loss: 0.4410 - val_accuracy: 0.8542\n",
            "Epoch 686/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2169 - accuracy: 0.9315 - val_loss: 0.4410 - val_accuracy: 0.8542\n",
            "Epoch 687/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1967 - accuracy: 0.9315 - val_loss: 0.4411 - val_accuracy: 0.8542\n",
            "Epoch 688/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2043 - accuracy: 0.9271 - val_loss: 0.4405 - val_accuracy: 0.8542\n",
            "Epoch 689/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2025 - accuracy: 0.9256 - val_loss: 0.4414 - val_accuracy: 0.8542\n",
            "Epoch 690/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1805 - accuracy: 0.9405 - val_loss: 0.4420 - val_accuracy: 0.8542\n",
            "Epoch 691/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2202 - accuracy: 0.9286 - val_loss: 0.4422 - val_accuracy: 0.8576\n",
            "Epoch 692/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1981 - accuracy: 0.9286 - val_loss: 0.4421 - val_accuracy: 0.8576\n",
            "Epoch 693/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2186 - accuracy: 0.9360 - val_loss: 0.4414 - val_accuracy: 0.8542\n",
            "Epoch 694/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2020 - accuracy: 0.9271 - val_loss: 0.4405 - val_accuracy: 0.8542\n",
            "Epoch 695/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2018 - accuracy: 0.9226 - val_loss: 0.4398 - val_accuracy: 0.8576\n",
            "Epoch 696/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2010 - accuracy: 0.9271 - val_loss: 0.4416 - val_accuracy: 0.8542\n",
            "Epoch 697/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2067 - accuracy: 0.9211 - val_loss: 0.4404 - val_accuracy: 0.8542\n",
            "Epoch 698/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2039 - accuracy: 0.9345 - val_loss: 0.4416 - val_accuracy: 0.8542\n",
            "Epoch 699/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2074 - accuracy: 0.9360 - val_loss: 0.4420 - val_accuracy: 0.8542\n",
            "Epoch 700/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2068 - accuracy: 0.9271 - val_loss: 0.4413 - val_accuracy: 0.8542\n",
            "Epoch 701/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2109 - accuracy: 0.9167 - val_loss: 0.4411 - val_accuracy: 0.8542\n",
            "Epoch 702/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2021 - accuracy: 0.9301 - val_loss: 0.4429 - val_accuracy: 0.8542\n",
            "Epoch 703/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1953 - accuracy: 0.9271 - val_loss: 0.4406 - val_accuracy: 0.8542\n",
            "Epoch 704/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1853 - accuracy: 0.9360 - val_loss: 0.4412 - val_accuracy: 0.8542\n",
            "Epoch 705/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1861 - accuracy: 0.9345 - val_loss: 0.4414 - val_accuracy: 0.8542\n",
            "Epoch 706/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.1906 - accuracy: 0.9494 - val_loss: 0.4420 - val_accuracy: 0.8542\n",
            "Epoch 707/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1926 - accuracy: 0.9271 - val_loss: 0.4413 - val_accuracy: 0.8542\n",
            "Epoch 708/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1902 - accuracy: 0.9435 - val_loss: 0.4390 - val_accuracy: 0.8542\n",
            "Epoch 709/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2028 - accuracy: 0.9315 - val_loss: 0.4394 - val_accuracy: 0.8542\n",
            "Epoch 710/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1990 - accuracy: 0.9241 - val_loss: 0.4404 - val_accuracy: 0.8542\n",
            "Epoch 711/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2297 - accuracy: 0.9182 - val_loss: 0.4406 - val_accuracy: 0.8542\n",
            "Epoch 712/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1981 - accuracy: 0.9226 - val_loss: 0.4423 - val_accuracy: 0.8542\n",
            "Epoch 713/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1767 - accuracy: 0.9464 - val_loss: 0.4414 - val_accuracy: 0.8542\n",
            "Epoch 714/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1904 - accuracy: 0.9256 - val_loss: 0.4398 - val_accuracy: 0.8542\n",
            "Epoch 715/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2161 - accuracy: 0.9241 - val_loss: 0.4417 - val_accuracy: 0.8542\n",
            "Epoch 716/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.1973 - accuracy: 0.9241 - val_loss: 0.4425 - val_accuracy: 0.8542\n",
            "Epoch 717/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.2025 - accuracy: 0.9286 - val_loss: 0.4405 - val_accuracy: 0.8542\n",
            "Epoch 718/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1799 - accuracy: 0.9286 - val_loss: 0.4405 - val_accuracy: 0.8542\n",
            "Epoch 719/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1901 - accuracy: 0.9226 - val_loss: 0.4409 - val_accuracy: 0.8542\n",
            "Epoch 720/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2043 - accuracy: 0.9286 - val_loss: 0.4409 - val_accuracy: 0.8542\n",
            "Epoch 721/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1950 - accuracy: 0.9286 - val_loss: 0.4419 - val_accuracy: 0.8542\n",
            "Epoch 722/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1857 - accuracy: 0.9345 - val_loss: 0.4413 - val_accuracy: 0.8542\n",
            "Epoch 723/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1842 - accuracy: 0.9435 - val_loss: 0.4412 - val_accuracy: 0.8542\n",
            "Epoch 724/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2023 - accuracy: 0.9330 - val_loss: 0.4419 - val_accuracy: 0.8542\n",
            "Epoch 725/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1938 - accuracy: 0.9390 - val_loss: 0.4423 - val_accuracy: 0.8542\n",
            "Epoch 726/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1845 - accuracy: 0.9375 - val_loss: 0.4438 - val_accuracy: 0.8542\n",
            "Epoch 727/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2011 - accuracy: 0.9375 - val_loss: 0.4445 - val_accuracy: 0.8542\n",
            "Epoch 728/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1830 - accuracy: 0.9479 - val_loss: 0.4436 - val_accuracy: 0.8542\n",
            "Epoch 729/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1818 - accuracy: 0.9524 - val_loss: 0.4428 - val_accuracy: 0.8542\n",
            "Epoch 730/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.1725 - accuracy: 0.9435 - val_loss: 0.4424 - val_accuracy: 0.8542\n",
            "Epoch 731/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1785 - accuracy: 0.9315 - val_loss: 0.4414 - val_accuracy: 0.8542\n",
            "Epoch 732/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2131 - accuracy: 0.9196 - val_loss: 0.4403 - val_accuracy: 0.8542\n",
            "Epoch 733/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1951 - accuracy: 0.9301 - val_loss: 0.4393 - val_accuracy: 0.8542\n",
            "Epoch 734/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1948 - accuracy: 0.9330 - val_loss: 0.4381 - val_accuracy: 0.8542\n",
            "Epoch 735/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2187 - accuracy: 0.9330 - val_loss: 0.4374 - val_accuracy: 0.8542\n",
            "Epoch 736/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1851 - accuracy: 0.9449 - val_loss: 0.4375 - val_accuracy: 0.8542\n",
            "Epoch 737/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2007 - accuracy: 0.9405 - val_loss: 0.4391 - val_accuracy: 0.8542\n",
            "Epoch 738/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1883 - accuracy: 0.9330 - val_loss: 0.4366 - val_accuracy: 0.8542\n",
            "Epoch 739/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1892 - accuracy: 0.9435 - val_loss: 0.4372 - val_accuracy: 0.8542\n",
            "Epoch 740/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1997 - accuracy: 0.9330 - val_loss: 0.4377 - val_accuracy: 0.8542\n",
            "Epoch 741/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1843 - accuracy: 0.9435 - val_loss: 0.4372 - val_accuracy: 0.8542\n",
            "Epoch 742/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2061 - accuracy: 0.9286 - val_loss: 0.4387 - val_accuracy: 0.8542\n",
            "Epoch 743/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1923 - accuracy: 0.9301 - val_loss: 0.4406 - val_accuracy: 0.8542\n",
            "Epoch 744/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1978 - accuracy: 0.9256 - val_loss: 0.4409 - val_accuracy: 0.8542\n",
            "Epoch 745/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1979 - accuracy: 0.9390 - val_loss: 0.4402 - val_accuracy: 0.8542\n",
            "Epoch 746/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1968 - accuracy: 0.9375 - val_loss: 0.4410 - val_accuracy: 0.8542\n",
            "Epoch 747/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1909 - accuracy: 0.9315 - val_loss: 0.4392 - val_accuracy: 0.8542\n",
            "Epoch 748/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1910 - accuracy: 0.9315 - val_loss: 0.4395 - val_accuracy: 0.8542\n",
            "Epoch 749/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1790 - accuracy: 0.9405 - val_loss: 0.4409 - val_accuracy: 0.8542\n",
            "Epoch 750/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1772 - accuracy: 0.9405 - val_loss: 0.4390 - val_accuracy: 0.8542\n",
            "Epoch 751/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1918 - accuracy: 0.9330 - val_loss: 0.4406 - val_accuracy: 0.8542\n",
            "Epoch 752/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1812 - accuracy: 0.9345 - val_loss: 0.4421 - val_accuracy: 0.8542\n",
            "Epoch 753/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1940 - accuracy: 0.9226 - val_loss: 0.4415 - val_accuracy: 0.8542\n",
            "Epoch 754/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1837 - accuracy: 0.9375 - val_loss: 0.4427 - val_accuracy: 0.8542\n",
            "Epoch 755/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1941 - accuracy: 0.9375 - val_loss: 0.4424 - val_accuracy: 0.8542\n",
            "Epoch 756/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2043 - accuracy: 0.9405 - val_loss: 0.4411 - val_accuracy: 0.8542\n",
            "Epoch 757/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1871 - accuracy: 0.9286 - val_loss: 0.4407 - val_accuracy: 0.8542\n",
            "Epoch 758/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.2018 - accuracy: 0.9226 - val_loss: 0.4404 - val_accuracy: 0.8542\n",
            "Epoch 759/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1875 - accuracy: 0.9315 - val_loss: 0.4409 - val_accuracy: 0.8542\n",
            "Epoch 760/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2222 - accuracy: 0.9196 - val_loss: 0.4410 - val_accuracy: 0.8542\n",
            "Epoch 761/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1868 - accuracy: 0.9435 - val_loss: 0.4401 - val_accuracy: 0.8542\n",
            "Epoch 762/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2011 - accuracy: 0.9375 - val_loss: 0.4421 - val_accuracy: 0.8542\n",
            "Epoch 763/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1825 - accuracy: 0.9360 - val_loss: 0.4403 - val_accuracy: 0.8576\n",
            "Epoch 764/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1976 - accuracy: 0.9271 - val_loss: 0.4413 - val_accuracy: 0.8542\n",
            "Epoch 765/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1997 - accuracy: 0.9152 - val_loss: 0.4404 - val_accuracy: 0.8542\n",
            "Epoch 766/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1917 - accuracy: 0.9390 - val_loss: 0.4403 - val_accuracy: 0.8542\n",
            "Epoch 767/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1960 - accuracy: 0.9301 - val_loss: 0.4391 - val_accuracy: 0.8542\n",
            "Epoch 768/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1830 - accuracy: 0.9390 - val_loss: 0.4392 - val_accuracy: 0.8542\n",
            "Epoch 769/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.1894 - accuracy: 0.9286 - val_loss: 0.4387 - val_accuracy: 0.8542\n",
            "Epoch 770/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2144 - accuracy: 0.9301 - val_loss: 0.4401 - val_accuracy: 0.8542\n",
            "Epoch 771/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2043 - accuracy: 0.9167 - val_loss: 0.4428 - val_accuracy: 0.8542\n",
            "Epoch 772/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2044 - accuracy: 0.9315 - val_loss: 0.4422 - val_accuracy: 0.8542\n",
            "Epoch 773/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2044 - accuracy: 0.9182 - val_loss: 0.4410 - val_accuracy: 0.8542\n",
            "Epoch 774/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2078 - accuracy: 0.9226 - val_loss: 0.4421 - val_accuracy: 0.8542\n",
            "Epoch 775/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1849 - accuracy: 0.9345 - val_loss: 0.4415 - val_accuracy: 0.8576\n",
            "Epoch 776/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1755 - accuracy: 0.9435 - val_loss: 0.4409 - val_accuracy: 0.8576\n",
            "Epoch 777/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1830 - accuracy: 0.9360 - val_loss: 0.4395 - val_accuracy: 0.8576\n",
            "Epoch 778/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1769 - accuracy: 0.9405 - val_loss: 0.4395 - val_accuracy: 0.8542\n",
            "Epoch 779/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1767 - accuracy: 0.9435 - val_loss: 0.4390 - val_accuracy: 0.8542\n",
            "Epoch 780/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1965 - accuracy: 0.9301 - val_loss: 0.4408 - val_accuracy: 0.8542\n",
            "Epoch 781/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1870 - accuracy: 0.9167 - val_loss: 0.4411 - val_accuracy: 0.8542\n",
            "Epoch 782/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2009 - accuracy: 0.9286 - val_loss: 0.4403 - val_accuracy: 0.8542\n",
            "Epoch 783/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1888 - accuracy: 0.9286 - val_loss: 0.4397 - val_accuracy: 0.8542\n",
            "Epoch 784/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1847 - accuracy: 0.9420 - val_loss: 0.4400 - val_accuracy: 0.8542\n",
            "Epoch 785/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1726 - accuracy: 0.9360 - val_loss: 0.4391 - val_accuracy: 0.8542\n",
            "Epoch 786/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2069 - accuracy: 0.9241 - val_loss: 0.4378 - val_accuracy: 0.8542\n",
            "Epoch 787/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1803 - accuracy: 0.9449 - val_loss: 0.4356 - val_accuracy: 0.8542\n",
            "Epoch 788/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1842 - accuracy: 0.9271 - val_loss: 0.4366 - val_accuracy: 0.8542\n",
            "Epoch 789/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2040 - accuracy: 0.9196 - val_loss: 0.4372 - val_accuracy: 0.8542\n",
            "Epoch 790/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1805 - accuracy: 0.9301 - val_loss: 0.4374 - val_accuracy: 0.8542\n",
            "Epoch 791/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1937 - accuracy: 0.9330 - val_loss: 0.4371 - val_accuracy: 0.8542\n",
            "Epoch 792/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1987 - accuracy: 0.9271 - val_loss: 0.4354 - val_accuracy: 0.8542\n",
            "Epoch 793/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2027 - accuracy: 0.9241 - val_loss: 0.4365 - val_accuracy: 0.8542\n",
            "Epoch 794/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1694 - accuracy: 0.9568 - val_loss: 0.4383 - val_accuracy: 0.8542\n",
            "Epoch 795/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1857 - accuracy: 0.9345 - val_loss: 0.4398 - val_accuracy: 0.8542\n",
            "Epoch 796/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1701 - accuracy: 0.9420 - val_loss: 0.4394 - val_accuracy: 0.8542\n",
            "Epoch 797/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1991 - accuracy: 0.9286 - val_loss: 0.4381 - val_accuracy: 0.8542\n",
            "Epoch 798/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2236 - accuracy: 0.9182 - val_loss: 0.4390 - val_accuracy: 0.8542\n",
            "Epoch 799/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1969 - accuracy: 0.9330 - val_loss: 0.4376 - val_accuracy: 0.8542\n",
            "Epoch 800/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2011 - accuracy: 0.9345 - val_loss: 0.4374 - val_accuracy: 0.8542\n",
            "Epoch 801/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1791 - accuracy: 0.9449 - val_loss: 0.4381 - val_accuracy: 0.8542\n",
            "Epoch 802/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2092 - accuracy: 0.9241 - val_loss: 0.4391 - val_accuracy: 0.8542\n",
            "Epoch 803/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1907 - accuracy: 0.9286 - val_loss: 0.4394 - val_accuracy: 0.8507\n",
            "Epoch 804/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1874 - accuracy: 0.9390 - val_loss: 0.4402 - val_accuracy: 0.8507\n",
            "Epoch 805/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1958 - accuracy: 0.9360 - val_loss: 0.4417 - val_accuracy: 0.8507\n",
            "Epoch 806/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1807 - accuracy: 0.9330 - val_loss: 0.4407 - val_accuracy: 0.8507\n",
            "Epoch 807/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1963 - accuracy: 0.9286 - val_loss: 0.4408 - val_accuracy: 0.8507\n",
            "Epoch 808/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1751 - accuracy: 0.9390 - val_loss: 0.4416 - val_accuracy: 0.8507\n",
            "Epoch 809/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1811 - accuracy: 0.9464 - val_loss: 0.4388 - val_accuracy: 0.8507\n",
            "Epoch 810/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1920 - accuracy: 0.9360 - val_loss: 0.4381 - val_accuracy: 0.8507\n",
            "Epoch 811/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1875 - accuracy: 0.9196 - val_loss: 0.4382 - val_accuracy: 0.8542\n",
            "Epoch 812/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1850 - accuracy: 0.9360 - val_loss: 0.4371 - val_accuracy: 0.8542\n",
            "Epoch 813/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1831 - accuracy: 0.9315 - val_loss: 0.4410 - val_accuracy: 0.8542\n",
            "Epoch 814/1000\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.1675 - accuracy: 0.9435 - val_loss: 0.4386 - val_accuracy: 0.8542\n",
            "Epoch 815/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1853 - accuracy: 0.9345 - val_loss: 0.4382 - val_accuracy: 0.8507\n",
            "Epoch 816/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2185 - accuracy: 0.9152 - val_loss: 0.4370 - val_accuracy: 0.8507\n",
            "Epoch 817/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2029 - accuracy: 0.9390 - val_loss: 0.4385 - val_accuracy: 0.8542\n",
            "Epoch 818/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1792 - accuracy: 0.9509 - val_loss: 0.4380 - val_accuracy: 0.8542\n",
            "Epoch 819/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1932 - accuracy: 0.9435 - val_loss: 0.4382 - val_accuracy: 0.8507\n",
            "Epoch 820/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1930 - accuracy: 0.9360 - val_loss: 0.4369 - val_accuracy: 0.8542\n",
            "Epoch 821/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2061 - accuracy: 0.9286 - val_loss: 0.4371 - val_accuracy: 0.8542\n",
            "Epoch 822/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1796 - accuracy: 0.9420 - val_loss: 0.4361 - val_accuracy: 0.8542\n",
            "Epoch 823/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1969 - accuracy: 0.9420 - val_loss: 0.4370 - val_accuracy: 0.8542\n",
            "Epoch 824/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1782 - accuracy: 0.9435 - val_loss: 0.4374 - val_accuracy: 0.8542\n",
            "Epoch 825/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2009 - accuracy: 0.9315 - val_loss: 0.4377 - val_accuracy: 0.8507\n",
            "Epoch 826/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1817 - accuracy: 0.9345 - val_loss: 0.4374 - val_accuracy: 0.8542\n",
            "Epoch 827/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1781 - accuracy: 0.9405 - val_loss: 0.4386 - val_accuracy: 0.8507\n",
            "Epoch 828/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1715 - accuracy: 0.9494 - val_loss: 0.4393 - val_accuracy: 0.8507\n",
            "Epoch 829/1000\n",
            "21/21 [==============================] - 2s 82ms/step - loss: 0.1752 - accuracy: 0.9524 - val_loss: 0.4377 - val_accuracy: 0.8507\n",
            "Epoch 830/1000\n",
            "21/21 [==============================] - 2s 92ms/step - loss: 0.1778 - accuracy: 0.9375 - val_loss: 0.4363 - val_accuracy: 0.8507\n",
            "Epoch 831/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.1632 - accuracy: 0.9449 - val_loss: 0.4354 - val_accuracy: 0.8542\n",
            "Epoch 832/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1855 - accuracy: 0.9301 - val_loss: 0.4352 - val_accuracy: 0.8507\n",
            "Epoch 833/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1944 - accuracy: 0.9360 - val_loss: 0.4354 - val_accuracy: 0.8507\n",
            "Epoch 834/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1819 - accuracy: 0.9449 - val_loss: 0.4356 - val_accuracy: 0.8507\n",
            "Epoch 835/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1903 - accuracy: 0.9226 - val_loss: 0.4360 - val_accuracy: 0.8507\n",
            "Epoch 836/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2088 - accuracy: 0.9196 - val_loss: 0.4362 - val_accuracy: 0.8507\n",
            "Epoch 837/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1797 - accuracy: 0.9405 - val_loss: 0.4364 - val_accuracy: 0.8507\n",
            "Epoch 838/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1879 - accuracy: 0.9420 - val_loss: 0.4349 - val_accuracy: 0.8507\n",
            "Epoch 839/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1887 - accuracy: 0.9286 - val_loss: 0.4340 - val_accuracy: 0.8542\n",
            "Epoch 840/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1804 - accuracy: 0.9449 - val_loss: 0.4368 - val_accuracy: 0.8542\n",
            "Epoch 841/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1973 - accuracy: 0.9286 - val_loss: 0.4383 - val_accuracy: 0.8542\n",
            "Epoch 842/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1836 - accuracy: 0.9301 - val_loss: 0.4394 - val_accuracy: 0.8507\n",
            "Epoch 843/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1710 - accuracy: 0.9390 - val_loss: 0.4385 - val_accuracy: 0.8507\n",
            "Epoch 844/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1894 - accuracy: 0.9479 - val_loss: 0.4388 - val_accuracy: 0.8507\n",
            "Epoch 845/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1823 - accuracy: 0.9301 - val_loss: 0.4407 - val_accuracy: 0.8507\n",
            "Epoch 846/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1885 - accuracy: 0.9301 - val_loss: 0.4393 - val_accuracy: 0.8507\n",
            "Epoch 847/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1644 - accuracy: 0.9509 - val_loss: 0.4406 - val_accuracy: 0.8507\n",
            "Epoch 848/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.1970 - accuracy: 0.9271 - val_loss: 0.4411 - val_accuracy: 0.8507\n",
            "Epoch 849/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2011 - accuracy: 0.9167 - val_loss: 0.4409 - val_accuracy: 0.8507\n",
            "Epoch 850/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1725 - accuracy: 0.9435 - val_loss: 0.4407 - val_accuracy: 0.8507\n",
            "Epoch 851/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1940 - accuracy: 0.9271 - val_loss: 0.4408 - val_accuracy: 0.8507\n",
            "Epoch 852/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1634 - accuracy: 0.9435 - val_loss: 0.4387 - val_accuracy: 0.8507\n",
            "Epoch 853/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.1887 - accuracy: 0.9330 - val_loss: 0.4375 - val_accuracy: 0.8507\n",
            "Epoch 854/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2128 - accuracy: 0.9241 - val_loss: 0.4391 - val_accuracy: 0.8507\n",
            "Epoch 855/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1657 - accuracy: 0.9464 - val_loss: 0.4382 - val_accuracy: 0.8507\n",
            "Epoch 856/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1760 - accuracy: 0.9420 - val_loss: 0.4411 - val_accuracy: 0.8507\n",
            "Epoch 857/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1923 - accuracy: 0.9211 - val_loss: 0.4423 - val_accuracy: 0.8507\n",
            "Epoch 858/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1901 - accuracy: 0.9330 - val_loss: 0.4420 - val_accuracy: 0.8507\n",
            "Epoch 859/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1805 - accuracy: 0.9330 - val_loss: 0.4405 - val_accuracy: 0.8507\n",
            "Epoch 860/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1909 - accuracy: 0.9315 - val_loss: 0.4392 - val_accuracy: 0.8507\n",
            "Epoch 861/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1874 - accuracy: 0.9286 - val_loss: 0.4388 - val_accuracy: 0.8542\n",
            "Epoch 862/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1700 - accuracy: 0.9390 - val_loss: 0.4400 - val_accuracy: 0.8507\n",
            "Epoch 863/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1784 - accuracy: 0.9420 - val_loss: 0.4413 - val_accuracy: 0.8507\n",
            "Epoch 864/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2018 - accuracy: 0.9271 - val_loss: 0.4428 - val_accuracy: 0.8507\n",
            "Epoch 865/1000\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.1870 - accuracy: 0.9345 - val_loss: 0.4452 - val_accuracy: 0.8507\n",
            "Epoch 866/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1970 - accuracy: 0.9182 - val_loss: 0.4432 - val_accuracy: 0.8542\n",
            "Epoch 867/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.1827 - accuracy: 0.9345 - val_loss: 0.4440 - val_accuracy: 0.8542\n",
            "Epoch 868/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1697 - accuracy: 0.9390 - val_loss: 0.4445 - val_accuracy: 0.8542\n",
            "Epoch 869/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.1962 - accuracy: 0.9286 - val_loss: 0.4434 - val_accuracy: 0.8542\n",
            "Epoch 870/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1574 - accuracy: 0.9554 - val_loss: 0.4453 - val_accuracy: 0.8472\n",
            "Epoch 871/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1893 - accuracy: 0.9167 - val_loss: 0.4456 - val_accuracy: 0.8472\n",
            "Epoch 872/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1931 - accuracy: 0.9256 - val_loss: 0.4451 - val_accuracy: 0.8472\n",
            "Epoch 873/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1873 - accuracy: 0.9345 - val_loss: 0.4437 - val_accuracy: 0.8507\n",
            "Epoch 874/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1732 - accuracy: 0.9405 - val_loss: 0.4429 - val_accuracy: 0.8472\n",
            "Epoch 875/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1937 - accuracy: 0.9405 - val_loss: 0.4439 - val_accuracy: 0.8507\n",
            "Epoch 876/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1816 - accuracy: 0.9509 - val_loss: 0.4397 - val_accuracy: 0.8507\n",
            "Epoch 877/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1835 - accuracy: 0.9345 - val_loss: 0.4399 - val_accuracy: 0.8507\n",
            "Epoch 878/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1718 - accuracy: 0.9271 - val_loss: 0.4381 - val_accuracy: 0.8507\n",
            "Epoch 879/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1884 - accuracy: 0.9286 - val_loss: 0.4379 - val_accuracy: 0.8507\n",
            "Epoch 880/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1646 - accuracy: 0.9420 - val_loss: 0.4390 - val_accuracy: 0.8542\n",
            "Epoch 881/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2077 - accuracy: 0.9152 - val_loss: 0.4387 - val_accuracy: 0.8472\n",
            "Epoch 882/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2038 - accuracy: 0.9301 - val_loss: 0.4410 - val_accuracy: 0.8507\n",
            "Epoch 883/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1772 - accuracy: 0.9345 - val_loss: 0.4411 - val_accuracy: 0.8507\n",
            "Epoch 884/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1743 - accuracy: 0.9464 - val_loss: 0.4383 - val_accuracy: 0.8507\n",
            "Epoch 885/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1726 - accuracy: 0.9479 - val_loss: 0.4387 - val_accuracy: 0.8507\n",
            "Epoch 886/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1655 - accuracy: 0.9554 - val_loss: 0.4379 - val_accuracy: 0.8507\n",
            "Epoch 887/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1978 - accuracy: 0.9226 - val_loss: 0.4377 - val_accuracy: 0.8507\n",
            "Epoch 888/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2047 - accuracy: 0.9286 - val_loss: 0.4391 - val_accuracy: 0.8507\n",
            "Epoch 889/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1904 - accuracy: 0.9315 - val_loss: 0.4394 - val_accuracy: 0.8472\n",
            "Epoch 890/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1657 - accuracy: 0.9449 - val_loss: 0.4389 - val_accuracy: 0.8507\n",
            "Epoch 891/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1695 - accuracy: 0.9256 - val_loss: 0.4385 - val_accuracy: 0.8507\n",
            "Epoch 892/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1795 - accuracy: 0.9479 - val_loss: 0.4355 - val_accuracy: 0.8507\n",
            "Epoch 893/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1599 - accuracy: 0.9479 - val_loss: 0.4342 - val_accuracy: 0.8507\n",
            "Epoch 894/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1859 - accuracy: 0.9301 - val_loss: 0.4347 - val_accuracy: 0.8507\n",
            "Epoch 895/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1790 - accuracy: 0.9271 - val_loss: 0.4362 - val_accuracy: 0.8507\n",
            "Epoch 896/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1810 - accuracy: 0.9390 - val_loss: 0.4379 - val_accuracy: 0.8507\n",
            "Epoch 897/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1835 - accuracy: 0.9330 - val_loss: 0.4409 - val_accuracy: 0.8507\n",
            "Epoch 898/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1680 - accuracy: 0.9435 - val_loss: 0.4405 - val_accuracy: 0.8507\n",
            "Epoch 899/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1728 - accuracy: 0.9301 - val_loss: 0.4419 - val_accuracy: 0.8507\n",
            "Epoch 900/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.1824 - accuracy: 0.9241 - val_loss: 0.4408 - val_accuracy: 0.8507\n",
            "Epoch 901/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1790 - accuracy: 0.9315 - val_loss: 0.4405 - val_accuracy: 0.8507\n",
            "Epoch 902/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1686 - accuracy: 0.9464 - val_loss: 0.4388 - val_accuracy: 0.8507\n",
            "Epoch 903/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1736 - accuracy: 0.9375 - val_loss: 0.4394 - val_accuracy: 0.8507\n",
            "Epoch 904/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1793 - accuracy: 0.9390 - val_loss: 0.4389 - val_accuracy: 0.8507\n",
            "Epoch 905/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1980 - accuracy: 0.9271 - val_loss: 0.4365 - val_accuracy: 0.8507\n",
            "Epoch 906/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.1859 - accuracy: 0.9315 - val_loss: 0.4358 - val_accuracy: 0.8542\n",
            "Epoch 907/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1588 - accuracy: 0.9539 - val_loss: 0.4361 - val_accuracy: 0.8542\n",
            "Epoch 908/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1884 - accuracy: 0.9286 - val_loss: 0.4358 - val_accuracy: 0.8542\n",
            "Epoch 909/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1828 - accuracy: 0.9375 - val_loss: 0.4353 - val_accuracy: 0.8542\n",
            "Epoch 910/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1705 - accuracy: 0.9509 - val_loss: 0.4372 - val_accuracy: 0.8542\n",
            "Epoch 911/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1671 - accuracy: 0.9464 - val_loss: 0.4359 - val_accuracy: 0.8576\n",
            "Epoch 912/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1692 - accuracy: 0.9345 - val_loss: 0.4377 - val_accuracy: 0.8542\n",
            "Epoch 913/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1851 - accuracy: 0.9226 - val_loss: 0.4370 - val_accuracy: 0.8576\n",
            "Epoch 914/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1645 - accuracy: 0.9435 - val_loss: 0.4370 - val_accuracy: 0.8542\n",
            "Epoch 915/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1891 - accuracy: 0.9345 - val_loss: 0.4341 - val_accuracy: 0.8507\n",
            "Epoch 916/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1824 - accuracy: 0.9226 - val_loss: 0.4354 - val_accuracy: 0.8542\n",
            "Epoch 917/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1798 - accuracy: 0.9286 - val_loss: 0.4369 - val_accuracy: 0.8542\n",
            "Epoch 918/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1648 - accuracy: 0.9420 - val_loss: 0.4393 - val_accuracy: 0.8542\n",
            "Epoch 919/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1908 - accuracy: 0.9464 - val_loss: 0.4410 - val_accuracy: 0.8542\n",
            "Epoch 920/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1766 - accuracy: 0.9405 - val_loss: 0.4374 - val_accuracy: 0.8542\n",
            "Epoch 921/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1640 - accuracy: 0.9435 - val_loss: 0.4366 - val_accuracy: 0.8542\n",
            "Epoch 922/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1798 - accuracy: 0.9375 - val_loss: 0.4371 - val_accuracy: 0.8507\n",
            "Epoch 923/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2051 - accuracy: 0.9345 - val_loss: 0.4368 - val_accuracy: 0.8507\n",
            "Epoch 924/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1694 - accuracy: 0.9449 - val_loss: 0.4371 - val_accuracy: 0.8507\n",
            "Epoch 925/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.1684 - accuracy: 0.9375 - val_loss: 0.4382 - val_accuracy: 0.8542\n",
            "Epoch 926/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1704 - accuracy: 0.9375 - val_loss: 0.4381 - val_accuracy: 0.8542\n",
            "Epoch 927/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1391 - accuracy: 0.9554 - val_loss: 0.4376 - val_accuracy: 0.8507\n",
            "Epoch 928/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.2003 - accuracy: 0.9241 - val_loss: 0.4392 - val_accuracy: 0.8507\n",
            "Epoch 929/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1793 - accuracy: 0.9420 - val_loss: 0.4408 - val_accuracy: 0.8542\n",
            "Epoch 930/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1629 - accuracy: 0.9479 - val_loss: 0.4397 - val_accuracy: 0.8542\n",
            "Epoch 931/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1925 - accuracy: 0.9196 - val_loss: 0.4406 - val_accuracy: 0.8542\n",
            "Epoch 932/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2015 - accuracy: 0.9122 - val_loss: 0.4393 - val_accuracy: 0.8542\n",
            "Epoch 933/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1769 - accuracy: 0.9449 - val_loss: 0.4408 - val_accuracy: 0.8542\n",
            "Epoch 934/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1895 - accuracy: 0.9256 - val_loss: 0.4400 - val_accuracy: 0.8542\n",
            "Epoch 935/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1528 - accuracy: 0.9539 - val_loss: 0.4426 - val_accuracy: 0.8542\n",
            "Epoch 936/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1782 - accuracy: 0.9301 - val_loss: 0.4439 - val_accuracy: 0.8542\n",
            "Epoch 937/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1666 - accuracy: 0.9554 - val_loss: 0.4434 - val_accuracy: 0.8542\n",
            "Epoch 938/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1841 - accuracy: 0.9405 - val_loss: 0.4435 - val_accuracy: 0.8542\n",
            "Epoch 939/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1975 - accuracy: 0.9256 - val_loss: 0.4445 - val_accuracy: 0.8542\n",
            "Epoch 940/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.1992 - accuracy: 0.9315 - val_loss: 0.4432 - val_accuracy: 0.8542\n",
            "Epoch 941/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.1729 - accuracy: 0.9449 - val_loss: 0.4428 - val_accuracy: 0.8542\n",
            "Epoch 942/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1595 - accuracy: 0.9390 - val_loss: 0.4414 - val_accuracy: 0.8542\n",
            "Epoch 943/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1869 - accuracy: 0.9301 - val_loss: 0.4411 - val_accuracy: 0.8542\n",
            "Epoch 944/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1690 - accuracy: 0.9420 - val_loss: 0.4402 - val_accuracy: 0.8542\n",
            "Epoch 945/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1852 - accuracy: 0.9345 - val_loss: 0.4403 - val_accuracy: 0.8542\n",
            "Epoch 946/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1691 - accuracy: 0.9420 - val_loss: 0.4400 - val_accuracy: 0.8542\n",
            "Epoch 947/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1880 - accuracy: 0.9330 - val_loss: 0.4410 - val_accuracy: 0.8542\n",
            "Epoch 948/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1546 - accuracy: 0.9494 - val_loss: 0.4388 - val_accuracy: 0.8611\n",
            "Epoch 949/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1527 - accuracy: 0.9509 - val_loss: 0.4381 - val_accuracy: 0.8611\n",
            "Epoch 950/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1888 - accuracy: 0.9390 - val_loss: 0.4377 - val_accuracy: 0.8611\n",
            "Epoch 951/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1533 - accuracy: 0.9301 - val_loss: 0.4394 - val_accuracy: 0.8542\n",
            "Epoch 952/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1580 - accuracy: 0.9509 - val_loss: 0.4403 - val_accuracy: 0.8542\n",
            "Epoch 953/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1791 - accuracy: 0.9420 - val_loss: 0.4421 - val_accuracy: 0.8611\n",
            "Epoch 954/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1870 - accuracy: 0.9345 - val_loss: 0.4412 - val_accuracy: 0.8507\n",
            "Epoch 955/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1738 - accuracy: 0.9479 - val_loss: 0.4387 - val_accuracy: 0.8507\n",
            "Epoch 956/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1634 - accuracy: 0.9494 - val_loss: 0.4403 - val_accuracy: 0.8542\n",
            "Epoch 957/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1613 - accuracy: 0.9390 - val_loss: 0.4399 - val_accuracy: 0.8542\n",
            "Epoch 958/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1733 - accuracy: 0.9405 - val_loss: 0.4390 - val_accuracy: 0.8576\n",
            "Epoch 959/1000\n",
            "21/21 [==============================] - 2s 77ms/step - loss: 0.1620 - accuracy: 0.9583 - val_loss: 0.4400 - val_accuracy: 0.8646\n",
            "Epoch 960/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1665 - accuracy: 0.9405 - val_loss: 0.4399 - val_accuracy: 0.8576\n",
            "Epoch 961/1000\n",
            "21/21 [==============================] - 2s 80ms/step - loss: 0.1812 - accuracy: 0.9375 - val_loss: 0.4391 - val_accuracy: 0.8576\n",
            "Epoch 962/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1717 - accuracy: 0.9464 - val_loss: 0.4399 - val_accuracy: 0.8646\n",
            "Epoch 963/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1685 - accuracy: 0.9315 - val_loss: 0.4396 - val_accuracy: 0.8542\n",
            "Epoch 964/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1907 - accuracy: 0.9226 - val_loss: 0.4385 - val_accuracy: 0.8646\n",
            "Epoch 965/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1586 - accuracy: 0.9330 - val_loss: 0.4405 - val_accuracy: 0.8611\n",
            "Epoch 966/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1665 - accuracy: 0.9449 - val_loss: 0.4402 - val_accuracy: 0.8611\n",
            "Epoch 967/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1655 - accuracy: 0.9345 - val_loss: 0.4415 - val_accuracy: 0.8611\n",
            "Epoch 968/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1788 - accuracy: 0.9435 - val_loss: 0.4405 - val_accuracy: 0.8646\n",
            "Epoch 969/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1548 - accuracy: 0.9435 - val_loss: 0.4419 - val_accuracy: 0.8646\n",
            "Epoch 970/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1793 - accuracy: 0.9390 - val_loss: 0.4408 - val_accuracy: 0.8611\n",
            "Epoch 971/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1794 - accuracy: 0.9449 - val_loss: 0.4400 - val_accuracy: 0.8576\n",
            "Epoch 972/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1698 - accuracy: 0.9315 - val_loss: 0.4398 - val_accuracy: 0.8611\n",
            "Epoch 973/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1480 - accuracy: 0.9524 - val_loss: 0.4395 - val_accuracy: 0.8576\n",
            "Epoch 974/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1690 - accuracy: 0.9405 - val_loss: 0.4421 - val_accuracy: 0.8576\n",
            "Epoch 975/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1656 - accuracy: 0.9315 - val_loss: 0.4415 - val_accuracy: 0.8611\n",
            "Epoch 976/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1618 - accuracy: 0.9449 - val_loss: 0.4435 - val_accuracy: 0.8611\n",
            "Epoch 977/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1661 - accuracy: 0.9420 - val_loss: 0.4441 - val_accuracy: 0.8611\n",
            "Epoch 978/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1693 - accuracy: 0.9435 - val_loss: 0.4451 - val_accuracy: 0.8611\n",
            "Epoch 979/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1697 - accuracy: 0.9360 - val_loss: 0.4449 - val_accuracy: 0.8646\n",
            "Epoch 980/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1816 - accuracy: 0.9286 - val_loss: 0.4427 - val_accuracy: 0.8646\n",
            "Epoch 981/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1911 - accuracy: 0.9420 - val_loss: 0.4422 - val_accuracy: 0.8646\n",
            "Epoch 982/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1836 - accuracy: 0.9390 - val_loss: 0.4433 - val_accuracy: 0.8646\n",
            "Epoch 983/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1597 - accuracy: 0.9568 - val_loss: 0.4451 - val_accuracy: 0.8576\n",
            "Epoch 984/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1766 - accuracy: 0.9256 - val_loss: 0.4448 - val_accuracy: 0.8646\n",
            "Epoch 985/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1656 - accuracy: 0.9449 - val_loss: 0.4444 - val_accuracy: 0.8576\n",
            "Epoch 986/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1632 - accuracy: 0.9524 - val_loss: 0.4449 - val_accuracy: 0.8681\n",
            "Epoch 987/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1758 - accuracy: 0.9345 - val_loss: 0.4450 - val_accuracy: 0.8681\n",
            "Epoch 988/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1660 - accuracy: 0.9539 - val_loss: 0.4468 - val_accuracy: 0.8646\n",
            "Epoch 989/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1752 - accuracy: 0.9345 - val_loss: 0.4467 - val_accuracy: 0.8646\n",
            "Epoch 990/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1986 - accuracy: 0.9345 - val_loss: 0.4451 - val_accuracy: 0.8611\n",
            "Epoch 991/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.2030 - accuracy: 0.9286 - val_loss: 0.4451 - val_accuracy: 0.8646\n",
            "Epoch 992/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1583 - accuracy: 0.9479 - val_loss: 0.4447 - val_accuracy: 0.8646\n",
            "Epoch 993/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1699 - accuracy: 0.9375 - val_loss: 0.4473 - val_accuracy: 0.8646\n",
            "Epoch 994/1000\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.1464 - accuracy: 0.9539 - val_loss: 0.4466 - val_accuracy: 0.8681\n",
            "Epoch 995/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.1851 - accuracy: 0.9315 - val_loss: 0.4449 - val_accuracy: 0.8681\n",
            "Epoch 996/1000\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.1543 - accuracy: 0.9449 - val_loss: 0.4458 - val_accuracy: 0.8681\n",
            "Epoch 997/1000\n",
            "21/21 [==============================] - 2s 79ms/step - loss: 0.1841 - accuracy: 0.9330 - val_loss: 0.4471 - val_accuracy: 0.8681\n",
            "Epoch 998/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1825 - accuracy: 0.9271 - val_loss: 0.4475 - val_accuracy: 0.8646\n",
            "Epoch 999/1000\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2005 - accuracy: 0.9256 - val_loss: 0.4478 - val_accuracy: 0.8646\n",
            "Epoch 1000/1000\n",
            "21/21 [==============================] - 2s 78ms/step - loss: 0.1531 - accuracy: 0.9464 - val_loss: 0.4486 - val_accuracy: 0.8576\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs= 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snJGiBTF88xt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "7bad2e6d-c431-41a8-b313-9a37f1514140"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5UScCw4yqCt"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-7hD8v3qu8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0acfb8-c209-4017-a13c-1d72929a9840"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "288"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzkHQYukrfmS"
      },
      "outputs": [],
      "source": [
        "pred_li = [np.argmax(i) for i in pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx-gl8LgrvT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785a0e45-9cf9-4eac-f615-7920a03ea5c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "pred_li"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMHKCvBhrdSK"
      },
      "outputs": [],
      "source": [
        "test_li = [np.argmax(i) for i in y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJGsYDFnr767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0578c10a-56b1-4edb-a3c7-59d938587bb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "test_li"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAhoiApMq2iz"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "# print(confusion_matrix(test_li, pred_li))\n",
        "confusion_matrix = metrics.confusion_matrix(test_li, pred_li)\n",
        "\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"Cat\", \"dog\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj0OKRwNsm0F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e4719f8f-4751-48eb-f840-b9e4acebb8ce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "octlccYgY9hl"
      },
      "outputs": [],
      "source": [
        "new_img = '/content/drive/MyDrive/ResNet Data/ResNet Data/dog02.jpg'\n",
        "img_array = cv2.imread(new_img)\n",
        "# img_array = cv2.cvtColor(img_array,cv2.COLOR_GRAY2RGB)\n",
        "plt.imshow(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "812vtAziabKn"
      },
      "outputs": [],
      "source": [
        "new_array = cv2.resize(img_array, (64, 64))\n",
        "print(new_array.shape)\n",
        "test = np.expand_dims(new_array, axis = 0)\n",
        "print(test.shape)\n",
        "pred = model.predict(test)\n",
        "print(f'Predictions : {pred}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4iJ7rRBavQl"
      },
      "outputs": [],
      "source": [
        "print('Actual Input : ', new_img.split('/')[-1][:3].capitalize())\n",
        "if np.argmax(pred) == 1:\n",
        "  print('Model Predicted : Dog')\n",
        "else:\n",
        "  print('Model Predicted : Cat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCpG6pcRcS_G"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/ResNet Data/ResNet Data/Cats'\n",
        "path01 = '/content/drive/MyDrive/ResNet Data/ResNet Data/Dogs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdtuyVRPeWJS"
      },
      "outputs": [],
      "source": [
        "#Counting Data\n",
        "cat_li = []\n",
        "for img in os.listdir(path):\n",
        "    cat_li.append(img)\n",
        "\n",
        "dog_li = []\n",
        "for im in os.listdir(path01):\n",
        "    dog_li.append(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1636OnX2t6Px"
      },
      "outputs": [],
      "source": [
        "len(cat_li), len(dog_li)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUHakF-SuAjN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}